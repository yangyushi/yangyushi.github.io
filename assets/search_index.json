[
  {
    "id": "/code/2020/04/22/python.html",
    "title": "Python",
    "content": "The markdown post provides information about using Sphinx to build documentation for code projects, including the process and useful extensions. It also explains how to render code blocks and formulas in web pages using Sphinx. It discusses linking to Python documentation and provides examples of using the pybind11 library to improve code performance by rewriting slow Python code in C++ and creating a Python wrapper for it. It also explains how to install pybind11 and Eigen libraries and provides examples of using them. The post covers the basics of using the struct module to handle binary data in Python. It also explains the concept of byte order and the importance of memory alignment in computer architecture. The post provides an overview of decorators in Python and how to use them to add or modify functionality to functions or classes without modifying their code. It also covers how to use the os module to interact with the operating system, including file manipulation, process information, and environment variables. The post introduces the itertools module, which provides powerful tools for creating and manipulating iterators in Python, including infinite iterators, functional tools, combination tools, and grouping with groupby. It explains how to interact with SQLite databases using the sqlite3 module, including creating tables, inserting data, selecting data, updating and deleting data, and viewing and dropping tables. The post also covers basic concepts in Python, such as built-in functions like enumerate, zip, filter, and reduce, as well as dynamic typing and object references in Python. The keywords for this post are Sphinx, documentation, code, extensions, pybind11, performance, C++, struct, byte order, memory alignment, decorators, os module, itertools module, iterators, SQLite, sqlite3 module.The post discusses several topics including parameter passing in Python, closures, the `with` statement, serialization using `pickle`, memory management, networking using sockets, and metaprogramming.   In parameter passing, the behavior differs for immutable and mutable objects. For immutable objects, a new reference is created which doesnt affect the original object. For mutable objects, the original object can be modified.   Closures are functions that reference variables outside their scope and are returned as values. The environment variables of a closure are stored in the `__closure__` attribute of the function object.  The `with` statement is used to define a context within which specific operations are triggered. It provides a way to manage resources such as file objects by automatically closing them.  Serialization refers to the process of converting objects into a binary format that can be stored or transmitted. The `pickle` module is used to serialize objects in Python.   Memory management is handled automatically in Python through garbage collection. Objects with zero reference count are considered garbage and are collected based on the difference between allocated and deallocated objects.  Networking in Python can be done using sockets, which provide inter-process communication capabilities. The `socket` module is used to create and manage sockets.  Metaprogramming involves writing code that can manipulate or generate code at runtime. The `type` function is used to dynamically create classes, and metaclasses can be used to customize class creation and behavior.  The 10 most important keywords are: parameter passing, closures, `with`, `pickle`, memory management, sockets, metaprogramming, serialization, garbage collection, and context management."
  },
  {
    "id": "/code/2022/04/02/nlp-deep-learning.html",
    "title": "Tensorflow Applications",
    "content": "This markdown post provides detailed explanations on how to model time series and natural language processing using TensorFlow. For time series modeling, it explains the concept of time series and its applications such as forecasting, imputation and interpolation, anomaly detection, and pattern detection. It also discusses stationary and non-stationary time series, and provides examples of how to prepare the data using the `tf.data.Dataset` class in TensorFlow, including methods like `window`, `drop_remainder`, and `flat_map`. The post also covers training data preparation, including features and labels, shuffling, and batching. Additionally, it introduces different baseline models for time series forecasting, such as naive forecasting, moving average, and differencing. For natural language processing, the post explains the tokenization process using the `Tokenizer` class in TensorFlow, including encoding, handling out-of-vocabulary words, and padding. It then demonstrates how to learn the embedding representations of words using an embedding layer in a neural network model. The post covers various models for sequence modeling, including LSTM, 1D CNN, and bidirectional LSTM. It provides code examples for constructing these models and training them using different loss functions. Finally, the post shows how to generate new text using a trained language model by predicting the next word based on existing text. The keywords for this post include time series modeling, TensorFlow, forecasting, imputation, interpolation, anomaly detection, pattern detection, dataset, window, shuffle, batch, baseline models, tokenization, embedding, LSTM, 1D CNN, bidirectional LSTM, and text generation."
  },
  {
    "id": "/code/2021/04/14/cpp.html",
    "title": "C++",
    "content": "In this markdown post, the author discusses different techniques in C++ for iterating over collections. The post first introduces traditional looping techniques such as the basic `for` loop, `while` loop, and `do-while` loop. Then, it explains how to iterate over collections using pointers, iterators, and range-based `for` loops. Next, it covers methods for iterating over elements using function pointers, functors, and lambda functions. It also mentions using algorithms from the `<algorithm>` library that operate on iterator ranges. Finally, it briefly discusses parallel iteration using C++17s parallel algorithms. The author concludes by stating that while traditional looping mechanisms are still relevant, the techniques based on the Standard Template Library (STL) provide powerful, expressive, and often more readable ways to iterate over collections. The choice of technique depends on the specific requirements of the task, code clarity, and performance considerations. The 10 most important keywords in this post are: iteration, technique, C++, traditional loop, for loop, while loop, do-while loop, pointer-based iteration, STL-based iteration, lambda function, and parallel iteration."
  },
  {
    "id": "/sci/2022/05/07/quantitative-model.html",
    "title": "Quantitative Modeling",
    "content": "This content is a summary of the Fundamentals of Quantitative Modeling Coursera course. The purpose of the course is to expose learners to the language of modeling, different models, and the process of modeling. Models are formal descriptions of business processes that simplify complex structures and rely on assumptions. Examples of models include the diamond price as a function of weight, the spread of an epidemic, the relationship between demand and price, and the uptake of a new product in the market. Mathematical functions used in modeling include linear, exponential, power, and logistic functions. Models are used for prediction, forecasting, optimization, ranking and targeting, exploring what-if scenarios, interpreting coefficients, and sensitivity analysis. The benefits of modeling include identifying gaps in understanding, making assumptions explicit, having a well-defined description of the business process, creating an institutional memory, and providing decision support. The key steps in modeling are defining inputs and outputs, formulating the model, validating the model, fitting it for the purpose, and implementing the model. The content also covers linear models, constant proportionate growth, present and future value, continuous compounding, and optimization. It introduces probabilistic models, regression models, probability trees, Monte-Carlo simulation, Markov models, and common probability distributions. Lastly, it discusses the empirical rule for normal distribution and covers regression models, multiple regression, and logistic regression. The 10 most important keywords are modeling, models, assumptions, prediction, forecasting, optimization, ranking, sensitivity analysis, probability distributions, and regression."
  },
  {
    "id": "/code/2020/01/11/C.html",
    "title": "C 语言",
    "content": "This markdown post provides an overview of the C programming language, including the creation process of a C program, the structure of a C program, constants and variables, data types, operators, input/output, control flow structures such as loops and conditionals, arrays, pointers, and file operations. It explains concepts such as preprocessing directives, functions, constants, and variables. It covers different data types such as integers, floating-point numbers, characters, and strings, as well as operations that can be performed on them. It also introduces the concept of pointers, which are variables that store memory addresses, and how they can be used to manipulate data. The post mentions the use of the string library string.h for string operations. Finally, it demonstrates how to open, close, read, and write to files in C.  Keywords: C programming language, program creation process, program structure, constants, variables, data types, integers, floating-point numbers, characters, strings, arrays, pointers, file operations."
  },
  {
    "id": "/code/2017/07/22/javascript.html",
    "title": "Javascript",
    "content": "JavaScript is a scripting language that is used to add dynamic functionality to HTML web pages. It is executed by a JavaScript engine. JavaScript code can be placed in the `<script>` tags within the `<body>` or `<head>` section of an HTML page, or it can be stored as a separate .js file and included in the HTML page using the `<script src=file.js></script>` tag. JavaScript code in the `<head>` section is parsed before the page is rendered, while JavaScript code in the `<body>` section is executed when the code is reached during rendering, which can improve page load speed. Variables in JavaScript can be declared using the `var` keyword, or simply assigned a value without using `var`. JavaScript has different data types including strings, numbers, booleans, and arrays. String values can be enclosed in single or double quotes, and quotes can be used within a string. Numbers can be integer or decimal, and booleans can be either true or false. Arrays can store multiple values and can be accessed using index numbers. JavaScript provides various operators for arithmetic, comparison, and logical operations. Control statements like if/else, switch/case, and for/while loops are used for decision-making and iteration. Functions in JavaScript are defined using the `function` keyword, and they can take multiple parameters. Function calls can be used to execute the code within the function body, which can include other control statements and loops to perform complex operations. JavaScript is object-oriented, and every data in JavaScript can be considered an object with properties and methods. Properties are variables that reflect certain characteristics of the object, while methods are functions that perform specific actions. JavaScript provides various objects like String, Math, and Array, which have built-in properties and methods for string manipulation, mathematical calculations, and array operations. JavaScript can also interact with the Document Object Model (DOM), which is a programming interface for HTML documents. This allows JavaScript to dynamically manipulate the elements and attributes of an HTML document. Elements can be selected by their ID, name, or tag name using methods like getElementByID(), getElementByName(), and getElementsByTagName(). Attributes of elements can be accessed and modified using the getAttribute() and setAttribute() methods. Elements can be created using the createElement() method and appended to the document using the appendChild() method. Elements can be removed using the removeChild() method. The parentNode() method can be used to access the parent element of a node. By understanding these concepts and using the provided examples, a query service can be built using JavaScript, with the keywords including JavaScript, HTML, dynamic functionality, scripting language, HTML web pages, JavaScript engine, code placement, `<script>` tag, body, head, `<script src=file.js></script>`, parsing, rendering, variables, `var`, data types, strings, numbers, booleans, arrays, operators, arithmetic, comparison, logical, control statements, if/else, switch/case, for/while loops, functions, function calls, objects, properties, methods, String, Math, Array, DOM, ID, name, tag name, getElementByID(), getElementByName(), getElementsByTagName(), getAttribute(), setAttribute(), createElement(), appendChild(), removeChild(), parentNode()."
  },
  {
    "id": "/science/2020/07/03/stochastic-process.html",
    "title": "随机过程",
    "content": "The provided content discusses the concept of random processes, specifically focusing on continuous-time random processes. It introduces the concept of sample functions or sample paths, which are specific realizations of a random process. The content also discusses the concepts of cumulative distribution function (CDF), average function, auto-correlation function, cross-correlation function, and the properties of stationary processes, including strict-sense stationary and weak-sense stationary. It highlights the properties of the autocorrelation function of a weak-sense stationary process and the cross-covariance function of two independent random processes. Additionally, the content covers the concept of cyclostationary processes, including strict cyclostationary and weak-sense cyclostationary processes. The concept of stochastic calculus for random processes is introduced, emphasizing mean-square continuity and the differentiation and integration operations for random processes. The content further discusses jointly normal random variables, normal random vectors, and normal random processes. Counting processes and Poisson processes are also explained, including the definitions and properties of Poisson random variables. The arrival times and inter-arrival times of Poisson processes are shown to follow exponential distributions. The Gamma distribution is introduced as the distribution of the sum of independent exponential random variables. The content concludes with a simulation method for generating Poisson processes using exponential random variables.   Keywords: random processes, sample functions, continuous-time, CDF, average function, auto-correlation function, cross-correlation function, stationary processes, strict-sense stationary, weak-sense stationary, autocorrelation function, cross-covariance function, cyclostationary processes, stochastic calculus, mean-square continuity, differentiation, integration, jointly normal, normal random vectors, normal random processes, counting processes, Poisson processes, Poisson random variables, arrival times, inter-arrival times, exponential distribution, Gamma distribution, simulation method.  (Note: The long paragraph format adheres to the users requirement of using only English words and punctuations such as comma and dot. The summary aims to cover the major concepts and keywords from the provided content.)"
  },
  {
    "id": "/science/2022/01/18/math.html",
    "title": "数学",
    "content": "The first part of the content discusses multiple comparisons in statistics. It explains that the p-value represents the probability of the null hypothesis being true, and if we use a p-value of 0.05 as a threshold, then each individual statistical test has a 5% chance of error. When conducting multiple tests, the probability of making at least one error increases significantly. The content then introduces two methods to address this issue: the Bonferroni correction and the Benjamini-Hochberg procedure. The Bonferroni correction divides the p-value by the number of tests, while the Benjamini-Hochberg procedure controls the false discovery rate by adjusting the p-value based on a predetermined threshold. The second part of the content discusses Singular Value Decomposition (SVD) and its formula. SVD is a way to decompose a matrix into three matrices: U, Σ, and V. It explains that U and V are rotation matrices with orthonormal bases, and Σ represents the singular values. The content also discusses the relationship between SVD and eigenvectors/eigenvalues. The third part of the content explains Principal Component Analysis (PCA) and its purpose in data compression. It mentions that PCA aims to find a mapping matrix W that can reduce the dimensionality of the data while preserving its information. It also discusses the relationship between PCA and SVD. The last part of the content introduces the Nabla operator, also known as the gradient operator, and its applications in divergence, gradient, and curl calculations. It explains the formulas for each of these calculations and their meanings in vector fields. Additionally, it briefly mentions the Laplacian operator and its effect on vector fields.  Keywords: multiple comparisons, p-value, null hypothesis, Bonferroni correction, Benjamini-Hochberg procedure, Singular Value Decomposition, SVD, eigenvectors, eigenvalues, Principal Component Analysis, PCA, data compression, Nabla operator, gradient operator, divergence, gradient, curl, Laplacian operator."
  },
  {
    "id": "/code/2020/05/18/tcc-hpc.html",
    "title": "TCC on HPC",
    "content": "The topological cluster classification (TCC) is a tool used to measure the many-body correlation of supercooled liquid and gel systems. The documentation provided for setting up TCC is good for a laptop, but some modifications are needed to make it work on an HPC. The major steps to make TCC work on the BlueCrystal supercomputer at the University of Bristol are as follows: 1. Specify necessary packages in the `.bashrc` file, including GCC, Git, and CMake. 2. Download the source code of TCC from GitHub. 3. Compile TCC using CMake and make. 4. Run TCC in a specific project directory to obtain results. 5. Use TCC inside Python by installing the TCC wrapper and importing it in Python scripts.  The key words are: topological cluster classification, many-body correlation, supercooled liquid, gel systems, documentation, setup, laptop, HPC, BlueCrystal, packages, `.bashrc` file, GCC, Git, CMake, source code, compile, project directory, TCC wrapper, Python."
  },
  {
    "id": "/code/2019/12/01/html.html",
    "title": "HTML",
    "content": "This markdown post provides a detailed explanation of various HTML elements and their functionalities. It covers topics such as HTML text, attributes, text formatting, hypertext links, tables, images, lists, blocks, and layouts. It also includes examples and explanations for each topic. The post provides information on how to create HTML elements, use attributes, and format text. It explains how to add links to text and images, set the opening methods for links, add prompt text, and use anchors. It discusses how to create tables, define rows and cells, and use important table tags and attributes. It explains how to insert and align images, resize them, and create image maps. It covers ordered, unordered, and defined lists, as well as how to use div elements for layout purposes. It provides examples for both table-based and div-based layouts. Finally, it explains how to create HTML forms, including input fields, checkboxes, and radio buttons. The keywords for this post are HTML, element, attribute, text, formatting, link, table, image, list, block, layout, form."
  },
  {
    "id": "/code/2019/08/23/css.html",
    "title": "CSS",
    "content": "The post provides an introduction to CSS syntax and advanced syntax, covering basic selectors like element selector, id selector, class selector, and attribute selector. It also explains the difference between id and class, and provides examples of applying styles to backgrounds, text, links, lists, tables, and outlines. Additionally, it introduces the CSS box model and discusses positioning, including static, relative, absolute, fixed, and floating positioning. Finally, the post includes information about sizing elements and navigation using CSS. The keywords from this post are CSS syntax, basic selectors, advanced selectors, id selector, class selector, attribute selector, background, text, links, lists, tables, outlines, box model, positioning, sizing, navigation."
  },
  {
    "id": "/code/2017/04/05/mysql.html",
    "title": "MySQL 简介",
    "content": "This markdown post provides an introduction to databases and SQL, as well as an overview of MySQL and some basic commands. It explains that a database is a structured repository for organizing, storing, and managing data, while SQL is a language used for operating on databases. MySQL is introduced as a DBMS developed by MySQLAB and currently owned by Oracle. It is a relational database management system that stores data in different tables to increase speed and flexibility. The post also provides basic commands for opening the MySQL service, viewing databases, connecting to databases, viewing tables, and exiting. It then goes on to explain the process of creating a database and inserting data into tables. It introduces different data types in MySQL, such as INT, FLOAT, DOUBLE, ENUM, SET, DATE, TIME, YEAR, CHAR, VARCHAR, and TEXT. The post also includes instructions for creating tables and inserting data into them. It explains constraints such as primary key, default value, unique, foreign key, and not null, and provides examples of how to define and use them. The SELECT statement is explained in detail, including basic syntax, limiting conditions (e.g., using IN, NOT IN, and LIKE with wildcards), sorting, using built-in functions for calculations (e.g., COUNT, SUM, AVG, MAX, MIN), handling subqueries, and performing join queries. It also covers modifying and deleting tables, including adding, dropping, renaming, and changing the data type of columns. Other topics discussed include indexes, views, importing, exporting, backing up, and restoring databases. The most important keywords are databases, SQL, MySQL, commands, tables, data types, constraints, SELECT, sort, functions, subqueries, join queries, modifying, deleting, indexes, views, importing, exporting, backing up, and restoring.  Keywords: databases, SQL, MySQL, commands, tables, data types, constraints, SELECT, sort, functions, subqueries, join queries, modifying, deleting, indexes, views, importing, exporting, backing up, restoring"
  },
  {
    "id": "/science/2020/11/22/mathmatics-for-economists.html",
    "title": "Mathematics for Echonomists",
    "content": "This markdown post provides notes on various mathematical concepts. It covers topics such as properties of operations, inner product in Rn, open balls, open sets, intersection of open sets, sequences in Rn, convergence of sequences, closed sets, operations on closed sets, bounded and compact sets, functions in Rn, domain of a function, continuity, Weierstrass theorem, composite functions, and their domains. The notes include mathematical equations and examples to illustrate the concepts. The keywords for this post are: properties of operations, inner product in Rn, open ball, open set, intersection of open sets, sequences in Rn, convergence, closed set, bounded, compact, functions in Rn, domain, continuity, Weierstrass theorem, composite function."
  },
  {
    "id": "/code/2019/12/17/remove_perspective.html",
    "title": "Removing the Perspective",
    "content": "This markdown post provides a detailed explanation of a method to remove perspective distortion from an image using Python. The first step involves loading the image and measuring several points on the image to determine parallel and perpendicular lines. The code block displays the image with the measured points. Next, the line at infinity is calculated using the measured points. The code block displays the image with the line at infinity. Then, an affine rectified image is created by applying the transformation obtained from the line at infinity. The code block displays the affine rectified image. In the next step, coordinates are measured again to recover the information about perpendicular lines. The code block displays the measured coordinates on the affine rectified image. The homography from the affine image to a similar image is then calculated. The code block displays the similar image. Composing the transformation involves combining the homography with the affine transformation to obtain the matrix that transforms the projective image to the similar image. Finally, the matrix is applied to the original image to create the final result. The post includes code blocks and images to illustrate each step of the process. The 10 most important keywords are: perspective, image, Python, libraries, load, measurements, parallel, perpendicular, affine, and homography."
  },
  {
    "id": "/science/2019/05/17/arguments.html",
    "title": "论证笔记",
    "content": "The content provides an overview of arguments, their nature, structure, and types. It explains that an argument is a set of sentences in which one is said to be true and the others are offered as reasons to believe the truth of that one. The structure of an argument consists of a conclusion and premises, with the conclusion being the sentence said to be true and the premises being the sentences offered as reasons. Sets of sentences that have no relation or have a relation other than that characterizing an argument are not arguments. To make an argument, we need to identify the relationship between sentences. Arguments can be classified into deductive and inductive types. Deductive arguments have premises that guarantee the truth of their conclusions, while inductive arguments have premises that make their conclusions more or less probable. Deductive arguments can have the same form, and their validity depends on the form rather than the content. Inductive arguments rely on the assumption of the uniformity of nature. The content also briefly explains other forms of argumentation, such as analog arguments and cause arguments. The importance of setting out arguments logic-book-style is highlighted, as it helps identify hidden premises, remove irrelevancies and inconsistent terms, and evaluate the argument process. The steps for analyzing arguments are provided, which include identifying the conclusion and premises, adding suppressed premises, removing irrelevancies and inconsistent terms, and removing cross-references. The content emphasizes the need to understand the structure and form of arguments rather than just focusing on the content.   Keywords: argument, conclusion, premises, structure, deductive, inductive, form, content, analyze, evaluate"
  },
  {
    "id": "/science/2020/11/02/pbc_py.html",
    "title": "Pairwise distance with PBC",
    "content": "This markdown post discusses different implementations of the periodic boundary condition (PBC) for simulating systems in molecular dynamics or Monte-Carlo sampling. The PBC is used to maintain the volume fraction of the system. The post introduces three different methods for calculating pairwise distances with PBC. The first method is a straightforward approach using nested for loops, but it is slow. The second method utilizes the pdist function from the scipy package, resulting in faster computation. The third method, inspired by Allen  Tildesleys book, involves calculating the pairwise shifts and using numpy broadcasting for efficiency. The post provides code snippets for each method and compares their efficiency. The second method is found to be the most efficient. The post also explains the importance of considering short-ranged interactions in the calculation and mentions the use of cutoff values like the Lennard-Jones potential. The keywords for this post are: periodic boundary condition, simulation, molecular dynamics, Monte-Carlo sampling, pairwise distances, Lennard-Jones potential, straightforward way, faster implementation, efficient, numpy broadcasting, comparison."
  },
  {
    "id": "/code/2020/11/15/ml.html",
    "title": "机器学习",
    "content": "The post starts by introducing the concept of simplex in mathematics, denoted by Δ, which is a set of points in ℝ^K satisfying certain conditions. These conditions include non-negative components and the sum of all components being equal to one. The geometric interpretation of simplex in different dimensions is discussed, where it represents a line segment in 2D, a triangle in 3D, and a tetrahedron in 4D, and so on. The relationship between simplex and probability distributions is also highlighted, where a point in a (K-1)-dimensional simplex corresponds to a probability distribution over K outcomes/events. The concept of simplicial complex is introduced as an extension of simplex, which represents a set composed of vertices, line segments, triangles, and n-dimensional counterparts.   The second part of the post discusses nuclear norm and spectral norm in matrix operations. The nuclear norm, denoted as ||A||_*, is defined as the sum of singular values of matrix A. An example Python code is provided to compute the nuclear norm of a matrix using numpy. In addition, pseudo code is given to demonstrate nuclear norm minimization as a convex substitute for matrix rank in optimization problems. The spectral norm, denoted as ||A||_2, is defined as the maximum singular value of matrix A. Another example Python code is provided to compute the spectral norm of a matrix using numpy. Pseudo code is given to show how spectral norm can be used as a constraint in optimization problems to define the size or effect of a matrix. Finally, both nuclear norm and spectral norm are integrated into semidefinite programming (SDP) problems, and pseudo code is given to illustrate SDP with nuclear norm minimization.  The last part of the post discusses the Keras functional API in TensorFlow 2, which provides an alternative way to build neural network models compared to the sequential API. The procedural style of creating a model using the sequential API is compared to the functional style using an example. In the functional API, we create a model by defining the inputs, applying layers to the inputs, and specifying the outputs. The deep understanding of the functional API is highlighted by explaining the concept of layers as functions that are applied to inputs to obtain outputs. The post concludes with a note on creating a model without specifying the input shape, where an example is given and it is explained that the model cannot be summarized until it is built using `build()` or `fit()` with some data.   The 10 most important keywords are simplex, geometric interpretation, probability distributions, simplicial complex, nuclear norm, spectral norm, Python code, SDP, Keras functional API, sequential API."
  },
  {
    "id": "/science/2021/04/04/image-der.html",
    "title": "Modeling Confocal Images",
    "content": "The post describes a model for simulating and analyzing confocal microscopy images of particles. The model treats each particle as a hard sphere with an anisotropic Gaussian blur. The contribution of each particle to the image is determined by its intensity, a Platonic particle without blur, and a Gaussian kernel. The model is written in a pseudo-code that generates a confocal image based on the positions, radii, and intensity values of the particles. The post also introduces the derivative of the model, which can be used to minimize the difference between the model and experimental data. The derivative is derived mathematically, considering the difference between the experimental image and the simulation, as well as the weight for different voxels. The derivative is then simplified by ignoring the effect of the location of one particle on another. The post explains that the derivative can be used to evaluate the Jacobian matrix for least-square fitting, offering faster computation by considering only a small sub-image where the particle and its blurred version are non-zero. The post also mentions the implementation of the cost function in a tracking code and the use of least square optimization to update the particle locations. The 10 most important keywords are: confocal microscopy, particles, model, simulation, derivative, experimental data, least-square fitting, tracking code, optimization, particle locations."
  },
  {
    "id": "/science/2023/09/08/stat-phy.html",
    "title": "统计物理",
    "content": "This markdown post discusses the Van Hove correlation function in detail. The Van Hove correlation function calculates the average number of times a particle is found at a certain position at time t, given that another particle is located at a different position at time t=0. The function can also be written in terms of the density correlation. The post explains the relationship between the Van Hove function and the radial distribution function. It also divides the Van Hove function into self and distinct parts, which provide information about the probability of a particle moving a certain distance and the probability of two particles having a specific displacement, respectively. The post further discusses the normalization of the Van Hove function and its connection to the scaling hypothesis. The scaling hypothesis is explained, and its implications for the magnetic susceptibility and magnetization are described. The post derives several relationships based on the scaling hypothesis and presents the predictions made by the hypothesis. Overall, the post provides a comprehensive overview of the Van Hove correlation function and its connection to the scaling hypothesis in statistical mechanics.  Keywords: Van Hove, correlation function, density, spatial, temporal, radial distribution function, self, distinct, normalization, scaling hypothesis, magnetic susceptibility, magnetization, relationships, predictions, statistical mechanics"
  },
  {
    "id": "/science/2020/04/28/vicsek-noise.html",
    "title": "Noise in 3D Vicsek model",
    "content": "This post provides an explanation of how to generate noise for the implementation of the vanilla algorithm of the Vicsek model in 3D. The noise is generated by rotating a target direction vector using a random direction. In the 2D case, the rotation is done by adding a random angle to the vector. However, in the 3D case, a more complex process is involved. The post discusses the math equation for rotating vectors and shows the effect of the rotation. The next chapter focuses on generating 3D noise, which involves generating random vectors that point uniformly to a specific region. The Python code for generating the noise is provided, along with an explanation of the code. The post also explains how to perform the rotation operation using a rotation matrix. The rotation is broken down into three steps: transforming the basis, performing the rotation, and transforming back to the original basis. The post provides the necessary equations and explains the intuition behind the rotation. The importance of this post lies in its explanation of generating noise for the Vicsek model in 3D and the process of rotating vectors. The keywords are: Vicsek model, 3D, noise, rotation, math equation, random vectors, pink cap, uniform distribution, rotation matrix."
  },
  {
    "id": "/code/2021/12/17/raw-npy.html",
    "title": "Open NPY in ImageJ",
    "content": "This post provides instructions on how to correctly import NPY files, which are binary files containing numpy arrays, into ImageJ or FIJI software. The NPY file consists of a header section containing information about the array and a raw data section containing the actual values. To import the NPY file into ImageJ or FIJI, you need to use the File -> Import -> Raw option. In the import window, you need to input the correct values for width, height, and number of images, based on the shape and data type of the numpy array. It is important to note that the order of axes in ImageJ/FIJI is reversed compared to numpy, so you need to load the array as (Z, Y, X) instead of (X, Y, Z). The offset to the first image should be set to the header length of the NPY file, which is typically a number divisible by 16, such as 128. If the header length is not known, you can view it using a hex editor. The header length is calculated as the HEADER_LEN value in the NPY file plus 10. Alternatively, you can dump the array without the header using the tofile method in numpy, but you would need to remember the shape and data type of the array when loading the raw file. The 10 most important keywords are ImageJ, FIJI, Numpy, NPY file, import, raw data, header length, reversed order, offset, and tofile method."
  },
  {
    "id": "/code/2020/03/04/opencv-undistort.html",
    "title": "Opencv Camera Distortion",
    "content": "The content discusses the issue of understanding and using distortion coefficients in camera calibration. The author mentions that after calibrating a camera using a chessboard, one can undistort an image or features in the image using the obtained distortion coefficients. However, the author encounters two issues: 1) the meaning of the numbers in the distortion coefficients, and 2) how to use these numbers to distort and undistort features without calling functions in OpenCV. The author examines the equations provided in OpenCV and implements them to undistort points, but obtains strange results. The author then compares the equations with a MATLAB version, which contradicts the OpenCV version but appears to be correct. The author eventually finds the truth in the source code of OpenCV, where it is confirmed that the math equations in the OpenCV tutorial are incorrect. The author shares their correct implementation of undistorting points and presents the successful results.   Keywords: internal parameter, camera, calibration, chessboard, undistort, distortion coefficients, meaning, equations, implementation, strange results, MATLAB, OpenCV, truth, source code, undistort manually, successful results."
  },
  {
    "id": "/idea/2022/02/07/read.html",
    "title": "读书笔记",
    "content": "沉思录 is a book written by Marcus Aurelius, a Roman emperor and philosopher of the Stoic school. In one of the volumes, he shares a thought-provoking conjecture about death and its impact on others. The idea is that no person is so lucky that there wont be someone pleased with their death. This double negative statement suggests that even in death, there may be people who find happiness or benefit from it. This concept challenges our conventional expectations of how others would feel upon our death. Marcus Aurelius advises that when facing death, we should reflect on the fact that we are leaving a life where our efforts for others may not be fully appreciated. He encourages us to depart with contentment and maintain our character of kindness, love, and gentleness. He reminds us that our ability to change our thoughts is the only thing we truly have control over. This perspective aligns with the Stoic teachings of focusing on developing virtuous qualities without expecting friendship or fearing death. The content also mentions the Stoic school of philosophy and a video by The School of Life that introduces the concept of embracing dark thoughts to find inner calmness. Additionally, the post provides a summary of the book Failure to Logic: An Illustrated Guide and presents various fallacies and their explanations. The key themes are death, Stoic philosophy, Marcus Aurelius, reflections on ones character, the impact of death on others, and logical fallacies."
  },
  {
    "id": "/code/2020/06/26/cpp-library.html",
    "title": "Create a C++ Library",
    "content": "This markdown post provides a step-by-step explanation on how to create and use static and dynamic libraries in C++. The author begins by discussing their confusion about the C++ ecosystem and their frequent inability to successfully compile open-source libraries. They then introduce a code example consisting of three files: `hello_world.h`, `hello_world.cpp`, and `main.cpp`. The goal is to create a library for the `hello_world` class so that it can be used in `main.cpp`. The source code for each file is provided. The post then demonstrates how to compile the code both with and without the library. The normal way to compile is explained using a `compile.sh` script, and it is mentioned that an incorrect library path configuration is often the cause of compilation failures. The process of creating and using a static library is explained using a `static.sh` script, including the creation of an archive of object files and linking them inside the final executable. The process of creating and using a shared library is explained using a `dynamical.sh` script, including the compilation of the source file with shared option, creation of the shared library, and linking the library with `main.cpp` using specific command-line options. The important keywords from this post are: C++, library, source file, compile, static, dynamic, header file, object file, executable, compile options, library path configuration."
  },
  {
    "id": "/code/2023/09/09/enum-py-cpp.html",
    "title": "Enumeration in Python/C++",
    "content": "Enums are used to represent a set of named values, providing improved code readability and reducing errors by replacing magic numbers or strings with named constants. In Python, the `enum.Enum` module provides flexibility by allowing enum members to be associated with various constant values, such as integers, strings, or tuples. Python enums also offer type-safe comparisons and iterability, making it easy to traverse all enum members. Additionally, Python enums can have methods and attributes. Examples of Python enums include basic enumerations, enums with flexible values, auto value assignment, iteration, and the inclusion of methods within enums. In C++, enums have an integral underlying type and can specify the type (e.g., `char` or `int`). The C++11 `enum class` provides better type safety and scope management, and explicit casting is required to convert `enum class` members to integers. Examples of C++ enums include basic enumerations, scoped enums with specific underlying types, access and comparisons, and the creation of custom enums using classes. The 10 most important keywords are enumerations, enums, named values, constants, Python, `enum.Enum`, flexibility, type safety, iterability, and scoped enums."
  },
  {
    "id": "/code/2023/09/07/jupyter-notebook.html",
    "title": "Jupyter Notebook Tricks",
    "content": "The post begins with an explanation of how to reload modules in Jupyter Notebook. Adding `%load_ext autoreload` and `%autoreload 2` at the beginning of the notebook allows for immediate updates to the module code. Next, it discusses the installation and uninstallation of kernels for different versions of Python. By using the commands `pip install ipykernel` and `python -m ipykernel install --user --name NAME --display-name NAME`, multiple kernels with specific names can be installed separately. The post then explains how to insert and resize images in Jupyter Notebook. While the default method is `!(link_to_image)`, it results in fixed-sized images. To insert an image with a desired size, the user needs to write HTML code, such as `<img src=image alt=Drawing style=width: 200px;/>`. However, this method does not render properly on GitHub. Finally, the post provides steps to connect to the BlueCrystal server (HPC at the University of Bristol) using Jupyter Notebook. This involves starting the notebook on BlueCrystal and forwarding the remote port to the local machine. The post ends with instructions on how to use the notebook by copying a generated link into the browser. Keywords: reload modules, install/uninstall kernel, image insert and resize, connecting to server, BlueCrystal, Jupyter Notebook, autoreload, kernelspec, HTML, BlueCrystal server."
  },
  {
    "id": "/code/2020/03/02/vim-desktop.html",
    "title": "Vim Desktop in Ubuntu ",
    "content": "This markdown post provides instructions on how to create a `.desktop` file in the `~/.local/share/applications` folder in order to use the latest vim that is built from the source and enable editing files by clicking the file icon. The post explains that simply using the command `Exec=bash -c vim %F` in the `.desktop` file is not enough as it will prevent the desktop from starting up. To address this issue, the post suggests adding `;exec SHELL` after `vim %F` in the `Exec` command to prevent the terminal from closing. Additionally, to inherit custom environment variables from `~/.bashrc`, the `Exec` command should be modified to include `source ~/.bashrc  vim %F;exec SHELL`. It is important to place any environmental variable declarations before the code-block in the `.bashrc` file that checks if the terminal is running interactively. The post also provides the final version of the `.desktop` file, which includes the encoding, name, comment, terminal option, application type, icon, categories, and MIME type. The ten most important keywords are vim, desktop file, `Exec`, terminal, `source`, `.bashrc`, environment variables, file icon, custom environment, and `Exec` command."
  },
  {
    "id": "/code/2020/10/22/hpc.html",
    "title": "Useful Commands in HPC",
    "content": "The content provides a collection of useful commands and scripts for working with the High-Performance Computing (HPC) system. It includes instructions for transferring files between the local machine and the HPC using the scp command, where the username and host are stored in an environmental variable for convenience. There are also commands for checking file size in megabytes using ls -l and du -sh, copying a file to the clipboard using cat file | pbcopy, batch converting image formats with mogrify -format, using large memory on BC3 HPC system with memory specifications in the job script, getting file hash using shasum, md5, and openssl md5, displaying an image on BC3 using display, and configuring Vim compilation with various features enabled such as multibyte, ruby and python3 interpretation, cscope, and a custom prefix. The 10 most important keywords are HPC, transfer files, file size, clipboard, image format conversion, large memory, file hash, image display, Vim compilation, and commands.  "
  },
  {
    "id": "/code/2017/12/09/struct.html",
    "title": "Python Module Struct",
    "content": "The provided content explains the usage of the struct module in Python for working with binary data. It introduces three important functions: pack, calcsize, and unpack. The pack function is used to encode numerical data into formatted binary data, taking a format string and values as inputs. The calcsize function returns the size of the struct corresponding to the format string. The unpack function unpacks binary data from a buffer according to the format string, returning a tuple of values. The example code demonstrates the usage of these functions and shows how the packed data can be printed and unpacked. The 10 most important keywords are: struct module, binary data, pack, calcsize, unpack, format string, values, bytes object, buffer, and tuple."
  },
  {
    "id": "/code/2021/01/13/connect-pi.html",
    "title": "Connecting Raspeberry Pi",
    "content": "This post describes the process of connecting a Raspberry Pi to a Ubuntu PC via ethernet. The Raspberry Pi is running the Raspberry Pi OS (Jan 2021). The author shares their experience and the steps they took to establish the connection. They first enable all interfaces on the Raspberry Pi and then use the command `ssh pi@raspberrypi.local` to connect to it via SSH. They encounter some warnings and resolve them by using the command `ssh-keygen -f /home/yushi/.ssh/known_hosts -R raspberrypi.local`. They then retry the SSH command, enter the default password (`raspberry`), and successfully establish the SSH connection. They also mention the convenience of using VNC Viewer to access the Raspberry Pis desktop and explain how they installed and used it on their Ubuntu PC, entering the server address as `raspberrypi.local` and providing the username (`pi`) and password (`raspberry`). The post concludes with the author expressing the time it took them to figure everything out.   Keywords: Raspberry Pi, Ubuntu PC, ethernet, Raspberry Pi OS, SSH, VNC Viewer, connection, command, warnings, password."
  },
  {
    "id": "/code/2020/02/09/ffmpeg.html",
    "title": "Video Editing",
    "content": "The content is a markdown post that provides useful code for processing videos in the terminal using `ffmpeg`. The post includes various command-line scripts for cutting videos, getting the first frame from a video, changing the gamma of a file, dropping the sound, changing the frame rate, generating a video from images, checking the total frames of a video, checking the frame rate, and generating a GIF from images using ImageMagick. The post also mentions that memorizing these commands can be difficult. Some example commands are provided, along with explanations of the command options. The post is structured with a table of contents at the beginning and code blocks for each script. The keywords include `ffmpeg`, video processing, command-line, cutting videos, first frame, gamma, sound, frame rate, images, total frames, frame rate, and GIF generation."
  },
  {
    "id": "/work/2023/08/18/barcode.html",
    "title": "二代测序",
    "content": "The content provides information about using barcodes in sequencing to differentiate DNA fragments from different samples. DNA consists of two complementary strands, with each strand having a 5 end and a 3 end. The standard direction of DNA sequence is from the 5 end to the 3 end. Pair Ended (PE) sequencing provides sequence information from both ends of the fragment, allowing for analysis of fragment direction and distance. Examples are given for single-end barcode strategy, where a barcode is added to one end of the fragment, and double-end barcode strategy, where barcodes are added to both ends of the fragment. There is also a mention of single-read barcode strategy, where a barcode is added to a specific read in paired-end sequencing. The importance of barcodes is highlighted in helping with data splitting and classification. The 10 most important keywords are: barcode, sequencing, DNA, fragment, sample, pair ended, 5 end, 3 end, single-end, double-end."
  }
]