[
  {
    "id": "/code/2020/04/22/python.html",
    "title": "Python",
    "content": "The provided markdown post discusses the usage of the Sphinx documentation generator to build documentation for code. The author describes the process of using Sphinx to generate HTML webpages from text files, similar to using Jekyll. They provide a step-by-step guide for using Sphinx, including writing docstrings in code, generating the rst documentation for each package, and adding modules to the index. The author also mentions useful extensions for Sphinx, such as autodoc for generating documentation from code, napoleon for understanding Google-style docstrings, intersphinx for adding links to external documentation, and mathjax for rendering LaTeX equations in the documentation. The post also explains how to render code blocks and formulas in webpages using Sphinx. Additionally, the author discusses the use of the pybind11 library to accelerate Python code by rewriting slow parts in C++ and directly referencing them in Python scripts. They provide installation instructions and examples of how to use pybind11 to create Python modules from C++ code. The author also explains the benefits of using pybind11 to handle data conversions between Python and C++. Lastly, the post introduces the struct module for working with binary data in Python, the os module for interacting with the operating system, the subprocess module for running and communicating with external processes, the itertools module for working with iterators and generators, and the sqlite3 module for working with SQLite databases. The post provides examples and explanations of how to use these modules to perform various tasks. The author also mentions some basic concepts such as decorators, the usage of @ symbol to apply decorators to functions and classes, and the usage of dynamic typing in Python. Overall, the keyword summary for this post includes Sphinx, documentation, autodoc, napoleon, intersphinx, mathjax, pybind11, C++, eigen, structs, byte order, little-endian, big-endian, memory alignment, os, subprocess, iterators, itertools, databases, and sqlite3.Parameter Passing  In Python, the behavior of functions differs when handling immutable and mutable objects. For immutable objects, such as integers, the value of the object passed to a function will not be modified. In the example provided, the function `f` receives an integer `a` as a parameter, but changing the value of `x` inside the function does not affect the original value of `a`. However, for mutable objects, such as lists, passing the object to a function may change the original object. In the example provided, the function `f` modifies the value of the first element of the list `b` to 100, and this change is reflected in the original list. It is important to be careful when passing mutable objects to avoid unexpected modifications.   Closure  In Python, a closure is a function that references variables from its outer scope and is returned as a result. In the example provided, the function `line_conf` returns a function `line` that takes a variable `x` and returns the result of `a * x + b`. The variable `a` and `b` are stored in the “environment variables” of the closure and can be accessed when calling the returned function. The environment variables of a closure are stored in the `__closure__` attribute of the function object.  Context: with  Starting from Python 2.5, the “with” statement provides a syntax for defining the scope of an object and triggering specific operations upon entering or exiting this scope, such as allocating or releasing the object. The syntax is as follows: `with...as...`. For example, when using the `with` statement with a file object, the file is automatically closed when exiting the scope. This ensures that the file is properly closed and avoids resource leaks. The `with` statement works by calling the `__enter__()` method of the object upon entering the block, and the `__exit__()` method upon exiting the block. For file objects, the `__exit__()` method calls the `self.close()` method, so there is no need to manually close the file.  Serialization: pickle  In Python, all variables or functions are objects that are stored in memory, but they can be serialized (or pickled) and stored on disk. Serialized objects require the definition of their class to be able to recreate them. Built-in objects like integers or lists can be directly recreated, but for user-defined objects, the class definition needs to be provided. The `pickle` module provides functions to serialize and deserialize objects. The `pickle.dumps()` function serializes an object and returns a string representation of the object, which can be saved to a file. The `pickle.dump()` function saves an object directly to a file. To load a serialized object, the `pickle.load()` function is used.  Memory  In Python, variables are references to objects in memory. For example, when assigning `a = 1`, `a` is a reference to the integer object `1`. The `id()` function can be used to get the memory address of an object. Python optimizes commonly used small integers and short strings, so multiple references to the same object may have the same memory address. However, for larger numbers or strings, each reference may have a different memory address. Objects in Python also maintain a reference count, which represents how many references are pointing to the object. The `sys.getrefcount()` function can be used to get the reference count, but it returns a count that is one higher due to its own reference. Containers like lists or dictionaries hold references to other objects instead of the objects themselves. Objects can have circular references, forming a reference cycle. Garbage collection in Python automatically cleans up objects that are no longer in use.  Networking  To understand Python server frameworks like Django, Twisted, and web.py, it is important to understand the foundation of network communication: sockets. Sockets provide network-based communication between processes. By mastering sockets, developers can effectively use and design server frameworks. In Python, all things are objects, including classes. These classes have their own type, which is itself a metaclass called type. Metaclasses are advanced OOP techniques that enable metaprogramming. While most Python programs do not require metaclasses, they can be used for advanced manipulation. By understanding metaclasses and their usage, developers can have a deeper understanding of Python internals.  Metaprogramming  Metaprogramming is an advanced OOP technique that allows a program to understand or modify itself. In Python, classes are objects themselves and have a type, which is usually type. By defining custom metaclasses, it is possible to modify the behavior of a class creation process. The metaclass is defined by inheriting from type and implementing the `__new__()` method, which returns the newly created class. Custom metaclasses can modify the attributes and behavior of classes, allowing for advanced customization and behavior modification during class creation. While metaprogramming can be powerful, it is not commonly used in everyday programming and should be approached with caution.  Avoid Using Metaclasses  While metaclasses provide advanced capabilities for manipulating the class creation process, it is generally recommended to avoid using metaclasses unless there is a specific need. The majority of Python programs do not require metaclasses, and the complexity and potential for confusion make them unnecessary for most scenarios. In many cases, simpler techniques such as inheritance or decorators can achieve the desired results without the added complexity of metaclasses. It is important to weigh the benefits and drawbacks of using metaclasses and consider alternative approaches before deciding to use them.  The 10 most important keywords in the content are: parameter passing, closure, with, pickle, memory, networking, metaprogramming, metaclass, avoid, custom.",
    "sha256": "6fa0e31f93d4eac94cdd6add3b3d0445a19177f7574b44631c125f0a56afaf2c"
  },
  {
    "id": "/code/2021/04/14/cpp.html",
    "title": "C++",
    "content": "迭代是编程中的基础概念，而C++提供了许多技术来迭代集合，每种技术都有其细微差别和用例。传统的循环机制包括基本的For循环，当迭代次数事先已知时常用；While和Do-While循环，当迭代次数不是由索引严格定义，或者循环至少必须运行一次时使用；以及基于指针的迭代，直接访问内存，通常与C风格的数组一起使用。基于STL的迭代则包括基于迭代器的For循环，使用容器定义的迭代器直接访问元素；基于范围的For循环，C++11引入，用于简化容器遍历；使用函数指针和仿函数的std::for_each，在C++11的lambda函数之前，这些是常用的方法；使用Lambda的std::for_each，C++11之后，lambda函数提供了一种更简洁的使用std::for_each的方式；带迭代器的算法，<algorithm>中的STL算法在迭代器范围上操作；以及并行迭代，C++17引入了并行算法，用于多线程处理。虽然传统的循环机制仍然是相关的，尤其是对于更简单的任务或与内存紧密合作时，基于STL的技术提供了强大、表现力强和通常更易读的方式来迭代集合。选择技术应由任务的具体要求、所需的代码清晰度和性能考虑来驱动。最重要的关键词包括迭代、For循环、While循环、Do-While循环、指针、STL、迭代器、范围、函数指针、仿函数、Lambda、算法、并行迭代。",
    "sha256": "c5f1dfbd1ca011d5fdd09eea6dfe1f2d7a5afa8c7bff52acdb9ffea70fbc96f3"
  },
  {
    "id": "/code/2022/04/02/nlp-deep-learning.html",
    "title": "Tensorflow Applications",
    "content": "In this markdown post, the author discusses two topics: Modelling Time Series and Modelling Natural Language.   For Modelling Time Series, the author begins with an introduction to time series, which are ordered sequences of equally spaced values over time. The author then explains that machine learning can be used for various time series applications, including predicting the future, retracing the past, detecting anomalies, and finding patterns. The author describes the typical patterns found in time series, such as trends, seasonality, white noise, and auto-correlation. They also discuss non-stationary time series, which may not follow the typical patterns.   Next, the author explains how to prepare data for time series modelling using the tf.data.Dataset class in TensorFlow. They provide code examples for creating datasets and manipulating them using methods like window, drop_remainder, and flat_map. They also demonstrate how to prepare training data by splitting the features and labels from the dataset using the map method. The author shows how to shuffle the data and batch it for training.  The author then introduces different models for time series forecasting, including baseline models like naive forecasting, moving average, and differencing. They also explain how to use linear regression, MLP (multi-layer perceptron), simple RNN (recurrent neural network), and LSTM (long short term memory) models for time series modelling. They provide code examples for constructing each model using the Sequential API in TensorFlow.  Finally, the author discusses how to evaluate the performance of time series predictions using various metrics like mean squared error (mse), root mean squared error (rmse), mean absolute error (mae), and mean absolute percentage error (mape).  For Modelling Natural Language, the author starts with an introduction to natural language processing (NLP), which involves extracting information from languages. The author gives an example of predicting the sentiment of movie comments. They describe the tokenization process, which involves converting text to numbers, and explain how to handle out-of-vocabulary words and pad sequences to a fixed length. The author provides code examples using the Tokenizer and pad_sequences classes in TensorFlow.  Next, the author discusses learning word embeddings, which are vector representations of words that capture their meanings. They explain how to train an embedding network using a predictive model and show the code for constructing such a model using the Embedding layer in TensorFlow.  The author then explains how to model the sequence of words using LSTM and 1D CNN models. They provide code examples for constructing these models using the Sequential API in TensorFlow.  Finally, the author demonstrates how to generate new text using a trained network. They provide code examples for training a network to predict the next word based on existing texts and for using the trained network to generate text.  The 10 most important keywords are: time series, modelling, TensorFlow, dataset, window, LSTM, NLP, tokenization, embedding, and sequence modelling.",
    "sha256": "1ea9c7393b17cefb7c006b68de2b0912f48849eecdddbefd4d312778fe14d597"
  },
  {
    "id": "/sci/2022/05/07/quantitative-model.html",
    "title": "Quantitative Modeling",
    "content": "This markdown post is a note on the fundamentals of quantitative modeling. It covers various topics related to modeling, including the purpose of modeling, different types of models, mathematical functions used in modeling, how models are used for prediction and optimization, the benefits of modeling, key steps in modeling, and a vocabulary for modeling. It also focuses on specific topics such as linear models, probabilistic models, regression models, and logistic regression. In the section on linear models, it discusses the concepts of constant proportionate growth, present and future value, continuous compounding, and optimization using calculus. In the section on probabilistic models, it covers random variables, probability distributions, regression models, probability trees, Monte Carlo simulation, and Markov models. The note also provides information on common probability distributions and the empirical rule for normal distribution. The section on regression models introduces the concepts of single regression and multiple regression, as well as logistic regression for discrete variables. Overall, the note provides a comprehensive overview of the fundamentals of quantitative modeling. The 10 most important keywords are: modeling, models, quantitative, assumptions, equations, optimization, probability, regression, variables, and distributions.",
    "sha256": "ca55e725060cc1b451b2d1129b6d6c5ac5ed397dfad2ab236d069666a9f77f45"
  },
  {
    "id": "/code/2020/01/11/C.html",
    "title": "C 语言",
    "content": "The provided content discusses various concepts related to C programming. It starts with an introduction to the creation process of C programs, including editing, compiling, linking, and execution. The structure of C programs is explained, including the preprocessor directives and functions, with the main() function being the entry point of every C program. The content also covers constants and variables, including different types of constants (integer, real, and character) and variable naming conventions. Different data types, such as integers and floats, are explained in detail, including their size, range, and storage representation. The content also covers characters and strings, including ASCII codes, string manipulation functions, and string input/output formatting. Operators in C, such as arithmetic, increment/decrement, and mixed data types operations, are discussed. The content also covers sequential structure design, including while and for loops, nested loops, and loop termination. Arrays, including one-dimensional and two-dimensional arrays, as well as strings as character arrays, are explained. Pointers, including basic usage, operators, pointer types, and applications, such as modifying function arguments and accessing array elements using pointers, are covered. File operations, including opening, closing, writing, and reading files, are explained.  Keywords: C programming, editing, compiling, linking, execution, structure, preprocessor directives, functions, main() function, constants, variables, data types, integers, floats, characters, strings, operators, sequential structure, loops, arrays, pointers, file operations",
    "sha256": "9b7a8ba0cdc766c920628da4404e289b66b110e2333aaa3b770de7efb516efaa"
  },
  {
    "id": "/code/2017/07/22/javascript.html",
    "title": "Javascript",
    "content": "JavaScript是一种脚本语言，主要用于为HTML网页增加动态功能。可以将JavaScript代码放在HTML页面的`<script>`标签中，或者单独存储在一个.js文件中并通过`<script src=file.js></script>`引用。JavaScript中的变量可以使用`var`关键字进行声明，也可以直接使用变量名进行赋值。JavaScript可以处理多种数据类型，包括字符串、数字、布尔值和数组。字符串可以使用单引号或双引号括起来，数字可以带小数点或不带小数点，布尔值只有true和false两种取值。数组可以用于存储多个变量。  JavaScript提供了多种运算符，包括算术、比较和逻辑运算符。算术运算符用于执行数学运算，比较运算符用于比较两个值的大小关系，逻辑运算符用于评估多个表达式的真假值。JavaScript还支持条件语句、循环语句和函数。条件语句例如if/else判断和switch/case结构，循环语句例如for循环和while循环，函数可以定义和调用以实现特定功能。  JavaScript是基于对象的语言，事件是JavaScript程序中的重要部分。事件是鼠标或热键的动作，每个事件都会引发一个事件处理程序的动作。常见的事件包括单击、双击、获得焦点、失去焦点、鼠标移动等。可以通过在HTML标签中添加相应的事件处理程序来捕获和处理事件。  JavaScript的数据都可以视为对象，每个对象都有属性和方法。属性是变量，表示对象的特定性质，方法是函数，实现特定的功能。可以通过关键词function定义函数，函数可以有多个参数，可以在函数体内部使用各种语句实现复杂的功能。需要注意的是，如果多次使用function命令重复声明同一个函数，后面的声明会覆盖前面的声明。  DOM是文档对象模型的简称，它把HTML和XML文档解析成一系列的节点，通过树状结构表示文档的结构。可以通过ID、名字、标签名等属性选取元素，通过getAttribute和setAttribute方法获取和设置元素的属性，通过parentNode方法获取元素的父节点，通过createElement和appendChild方法创建和插入节点，通过removeChild方法删除节点。  其中最重要的10个关键字为：JavaScript、HTML、动态功能、变量、数据类型、运算符、逻辑控制语句、函数、事件、DOM。",
    "sha256": "147ab4c7f9f4c47529ab7f285570763b491baa38392addf2fbd8c38370615926"
  },
  {
    "id": "/science/2020/07/03/stochastic-process.html",
    "title": "随机过程",
    "content": "This is a summary of a markdown post about random processes and counting processes. The post introduces the concept of random processes, which are collections of random variables indexed by time. There are two types of random processes: continuous-time random processes, which have a continuous time index, and discrete-time random processes, which have a discrete time index. The post discusses various concepts related to random processes, such as the cumulative distribution function (CDF), mean function, autocorrelation function (ACF), and cross-correlation function. It also introduces the concept of stationary processes, which are random processes whose statistical properties do not change over time. The post further discusses the properties of stationary processes, such as the constant mean function and the time-invariant ACF. It then introduces cyclostationary processes, which are stationary processes with periodic properties. The post also covers topics such as random variable calculus, Gaussian random processes, counting processes, and the Poisson process. The Poisson process is a common type of counting process that models events occurring randomly with a fixed rate. The post explains the properties of the Poisson process and its relationship with exponential and gamma distributions. The post concludes by discussing methods for simulating Poisson processes. The ten most important keywords are: random processes, counting processes, continuous-time random processes, discrete-time random processes, stationary processes, autocorrelation function, cross-correlation function, Poisson process, cyclostationary processes, and gamma distribution.",
    "sha256": "5c0b9dcb35078342c59681a7a8e14698273257787b85fe68249a07cc9d7d1922"
  },
  {
    "id": "/science/2022/01/18/math.html",
    "title": "数学",
    "content": "Multiple Comparison:  In statistics, the P-value is the probability of the null hypothesis being true is 1 minus the P-value. If we use a significance level of P=0.05 to determine whether the null hypothesis is true or not, each individual test has a 5% chance of error.  If we perform multiple statistical tests in a project, the probability of having all tests be true is (1-P)^n, which means that as n becomes large, we are almost certain to make errors. Two methods are introduced to address the issue of multiple comparison and reduce the chance of false positives, but at the same time, increase the chance of false negatives. The decision to actively reduce false positives depends on the cost and needs to be determined by the individual.  Keywords: multiple comparison, statistics, P-value, null hypothesis, significance level, error, false positives, false negatives  Bonferroni Correction: Bonferroni Correction sets a new P-value as P = P/n to reduce the chance of false positives. However, this method has the disadvantage of setting many comparisons that do not fit the null hypothesis as null. Additionally, there is a historical problem when analyzing results from previous years.   Keywords: Bonferroni correction, false positives, false negative, P-value, null hypothesis, comparison, significance level  Benjamini-Hochberg procedure: The Benjamini-Hochberg procedure controls the false discovery rate by assigning an adjusted P-value to each statistical analysis. The adjusted P-value is calculated as (i/m)Q, where i is the position of the analysis in the sorted list of P-values, m is the total number of analyses, and Q is the false discovery rate. The statistical results are considered significant if their adjusted P-value is smaller than the set Q value. This method avoids accepting all null hypotheses when the number of tests is large.  Keywords: Benjamini-Hochberg procedure, false discovery rate, adjusted P-value, statistical analysis, Q value  Prism methods: In the software Prism, Bonferroni, Tukey, Dunnett, or Dunn methods can be selected. They all report adjusted P-values, which are used to determine if a particular test does not fit the null hypothesis within a multiple comparison family.  Keywords: Prism, Bonferroni, Tukey, Dunnett, Dunn, adjusted P-value, null hypothesis  SVD: Singular Value Decomposition (SVD) is a matrix factorization method commonly represented as A = UΣV^T, where U and V are unitary matrices. The columns/rows of U and V serve as the standard orthogonal bases of the vector space that contains the left and right singular vectors. Σ represents the corresponding singular values. SVD can also be related to the eigenvectors/values of a square matrix.  Keywords: Singular Value Decomposition, SVD, matrix, U, Σ, V, eigenvectors, eigenvalues  PCA: Principal Component Analysis (PCA) is used to compress data. It finds a matrix W that can map the data matrix X in high-dimensional space to a lower-dimensional space represented by matrix Y. Another matrix U is used to reconstruct Y back to a data matrix that is close to the original X. PCA aims to minimize the difference between X and U*Y. Different methods of PCA should be chosen based on the specific comparison scenario.  Keywords: Principal Component Analysis, PCA, data compression, matrix, W, U, X, Y  Vector differential operators: The Nabla (del) operator is a vector differential operator that can represent divergence, gradient, and curl. It is commonly denoted as ∇. Divergence (div), gradient (grad), and curl can be calculated using the Nabla operator. The Laplacian operator (∇^2) measures the curvature of a vector field and can be applied to both vector and scalar fields.  Keywords: vector differential operator, Nabla operator, divergence, gradient, curl, Laplacian, vector field, scalar field",
    "sha256": "428e80006e1a24745bde71e5cc80d5144281de8a915533d15829a8521f34600c"
  },
  {
    "id": "/code/2020/05/18/tcc-hpc.html",
    "title": "TCC on HPC",
    "content": "The topological cluster classification (TCC) is a novel tool used to measure the many-body correlations in supercooled liquid and gel systems. This post provides a guide on how to set up TCC on the BlueCrystal supercomputer at the University of Bristol. The general steps include specifying necessary packages in the `.bashrc` file, downloading the source code of TCC from GitHub, compiling TCC using CMake, running TCC directly inside a project directory, and using TCC inside Python. To use TCC on the BlueCrystal, the required packages (GCC, git, and CMake) are already available, but they need to be added to the `.bashrc` file. The modifications can be made using the Vim text editor by appending the necessary lines to the `.bashrc` file. After making the modifications, the `.bashrc` file needs to be sourced to apply the changes. The TCC source code can be downloaded from GitHub using the `git clone` command. To compile TCC, navigate to the TCC directory, create a build directory, run CMake with the appropriate install prefix, and execute the `make` and `make install` commands. Once TCC is compiled, it can be used by navigating to a project directory and running the `tcc` command. The software will then be executed, and the results will be displayed. Additionally, a Python wrapper for TCC is available, and it can be installed by running the `python setup.py install --user` or `pip install . --user` command. The TCC wrapper can then be imported in a Python script, and the TCC executable directory needs to be specified in the code. Finally, a sample Python script is provided to demonstrate the usage of the TCC wrapper. The 10 most important keywords are: topological cluster classification, supercooled liquid, gel systems, setup, BlueCrystal, `.bashrc`, source code, compile, project directory, Python wrapper.",
    "sha256": "175865b28c836ad882363929a094502e2bd5971a01afad90d3c30bd0a115bec9"
  },
  {
    "id": "/code/2019/12/01/html.html",
    "title": "HTML",
    "content": "In this markdown post, the author provides a detailed explanation of various HTML elements and their functionalities. The post starts with an introduction to HTML elements and their syntax. It explains how HTML elements consist of start tags, end tags, and content. The author also mentions that some HTML elements have empty content and can be closed using self-closing tags. The post then discusses the nesting of HTML elements and gives an example of wrapping HTML elements within each other.   Next, the author explains the concept of blank elements that do not have any content. Examples of blank elements are given, such as the `<br>` tag for line breaks. The author also mentions that in XHTML, XML, and future versions of HTML, all elements must be closed. The correct way to close a blank element is by adding a slash inside the start tag.   The post then covers HTML attributes and their usage within HTML elements. The author explains that attributes are defined in the start tags of HTML elements and consist of a name and a value. The value of an attribute should always be enclosed in quotes. Examples of attributes are provided, such as the `href` attribute in the `<a>` tag.   The post also discusses various text formatting elements in HTML, such as `<b>`, `<em>`, and `<small>`, and explains their functionalities. It provides an example of using the `<pre>` tag for displaying pre-formatted text with the same formatting as in the code.   The author then introduces the concept of styling HTML elements using the `style` attribute. It gives an example of styling a `<p>` tag with different text alignment, font-family, and color.   Next, the author explains HTML hypertext, starting with HTML links. The post provides examples of adding links to text and images and discusses opening methods for hyperlinks. It explains how the `target` attribute in the `<a>` tag can be used to specify whether the link should open in the same page or a new browser window. The post also mentions the use of the `title` attribute for displaying prompt text when the cursor is hovered over a hyperlink.   The author then introduces the concept of anchors for intra-page navigation. An example is given of using anchor tags to create jump links within the same page.   The post moves on to HTML tables, explaining their importance in web design and their structure using the `<table>`, `<tr>`, `<td>`, and `<th>` tags. An example of a basic HTML table is provided, along with important tags and attributes for customizing tables, such as `<caption>`, `cellpadding`, `bgcolor`, `rowspan`, and `colspan`.   The next topic covered is HTML images, explaining how to insert images using the `<img>` tag and the `src` attribute. The post provides examples of aligning images and resizing them using the `align`, `width`, and `height` attributes. It also introduces the concept of image maps, where different areas of an image can be linked to different locations.   The post then discusses HTML lists, explaining the syntax for ordered, unordered, and defined lists using the `<ol>`, `<ul>`, `<li>`, `<dt>`, and `<dd>` tags.   The concept of HTML blocks is introduced, explaining the difference between block-level and inline elements. The post provides examples of block-level elements like `<h1>`, `<p>`, `<ul>`, and `<table>`, and inline elements like `<b>`, `<td>`, `<a>`, and `<img>`.   Finally, the post covers HTML layout using tables and divs. It provides examples of creating layouts using the `<table>` and `<div>` elements, along with relevant tags and attributes for customizing the layout.   Keywords: HTML elements, syntax, start tag, end tag, content, empty content, self-closing tags, nesting, blank elements, attributes, text formatting, styling, HTML hypertext, links, opening methods, prompt text, anchors, HTML tables, structure, tags, attributes, HTML images, insertion, align, resize, image maps, HTML lists, ordered list, unordered list, defined list, HTML blocks, block-level elements, inline elements, layouts, tables, divs.",
    "sha256": "8aee7b947e624a5ddcb545f1520707e24029a9e65543fac5f40493e9b1de8279"
  },
  {
    "id": "/code/2019/08/23/css.html",
    "title": "CSS",
    "content": "The provided content is a tutorial on CSS (Cascading Style Sheets). It covers basic and advanced syntax and selectors, including the use of selectors for grouping and inheritance. It also explains different types of selectors, such as ID selectors, class selectors, and attribute selectors, as well as the differences between ID and class selectors. The tutorial further covers basic styling properties for background, text, links, lists, tables, and outlines. It also introduces the concept of the CSS box model, including positioning, floating, and sizing. Lastly, it provides information on advanced topics such as positioning and navigation. The 10 most important keywords are: CSS, selectors, syntax, ID selectors, class selectors, attribute selectors, box model, positioning, floating, and sizing.",
    "sha256": "24c0202c246108d01e346379fabb5eff78e226252a60e05d03f060e32d34da52"
  },
  {
    "id": "/code/2017/04/05/mysql.html",
    "title": "MySQL 简介",
    "content": "This markdown post provides an overview of databases and SQL. It introduces databases as warehouses that organize, store, and manage data using a structured query language called SQL. It also provides an introduction to MySQL, a relational database management system, which stores data in tables to increase speed and flexibility. The post goes on to explain basic commands such as starting the MySQL service, viewing databases, connecting to databases, and exiting. It then covers creating databases and tables, inserting data into tables, and explains the different data types in MySQL. The post also introduces various constraints such as primary keys, default values, unique constraints, foreign key constraints, and non-null constraints. It provides examples of creating and using these constraints. The post then explains the SELECT statement in detail, including basic syntax, using WHERE clauses, sorting results, using built-in functions for calculations, using subqueries, and performing join queries. It also covers modifying and deleting data, such as dropping databases and tables, renaming tables, modifying column properties, and changing column values. Additionally, the post briefly mentions indexing, views, importing data, exporting data, backing up databases, and restoring databases.   The 10 most important keywords are: databases, SQL, MySQL, tables, columns, constraints, SELECT, INSERT, UPDATE, and DELETE.",
    "sha256": "7c979e922e85a9166ab70cdff67a4f80fe8e7f94ab39a4c729b8f6a4b3ca629d"
  },
  {
    "id": "/science/2020/11/22/mathmatics-for-economists.html",
    "title": "Mathematics for Echonomists",
    "content": "This markdown post provides a summary of various mathematical concepts and properties. It starts with an introduction about the authors interest in learning math and mentions a course they are taking. The content is divided into different sections, starting with a section on the properties of operations, such as addition, multiplication, and scalar multiplications. The next section discusses the inner product in vector spaces, including the dot product and the norm of a vector. It also introduces the concept of an open ball and open sets in mathbbR^n. The intersection of open sets and its properties are explained next. Sequences in mathbbR^n and their convergence are discussed, followed by the concept of closed sets and their properties. The operations on closed sets are described, including the intersection and union. The concepts of bounded sets and compact sets are introduced, defining a compact set as a closed and bounded set. The discussion then moves on to functions in mathbbR^n, including their domains and continuity. The Weierstrass theorem is mentioned, stating that a continuous function on a closed interval attains its maximum and minimum values. The notion of composite functions and their continuity are explained, with an example involving the composition of two functions. The post concludes with a diagram illustrating the relationship between the domains and images of composite functions.   The 10 most important keywords are: properties of operations, inner product, open ball, open set, intersection of open sets, sequences, convergence, closed set, bounded set, compact set.",
    "sha256": "f29920c656f174fa8e872abc44d791d874fd35109a51eb23031f50ebd4952a8a"
  },
  {
    "id": "/code/2019/12/17/remove_perspective.html",
    "title": "Removing the Perspective",
    "content": "This post provides a detailed tutorial on how to remove perspective from an image using Python. The post begins by setting up the necessary libraries, including OpenCV, NumPy, PIL, and Matplotlib. It then demonstrates how to load an image using the PIL library. Next, it explains the importance of measuring several points on the image to identify parallel and orthogonal lines. The post includes code to visually represent these measurements on the image. It also explains the relationships between the measured lines. The next step is to calculate the line at infinity, which will be used to recover information about parallel lines in the image. The post provides code to calculate the line at infinity and visualizes it on the image. The homogeneous representation of the line at infinity is also presented. The post then proceeds to create an affine rectified image by applying the transformation obtained from the line at infinity. It provides code and an image showing the result. The next step is to measure coordinates again to ensure that perpendicular lines in real life are also perpendicular in the image. The post includes code and an image to illustrate the measurement results, noting that the perpendicular lines are not yet perpendicular in the image. The post then explains how to calculate the homography from the affine image to a similar image. It provides code and an image to demonstrate this calculation. The resulting similar image is shown, where the chessboard regains its original rectangular shape after the perspective removal. The post emphasizes that the result is not equivalent to an image taken from a top view, as the distances and angles are not invariant in real 3D space. Finally, the post concludes by explaining how to compose the transformation matrix to convert a projective image to a similar image. It provides code and an image showing the result.   The 10 most important keywords are: 1. Perspective 2. Python 3. Libraries 4. Image 5. Measurements 6. Parallel lines 7. Orthogonal lines 8. Affine transformation 9. Homography 10. Similar transformation",
    "sha256": "3141514a36f86e52048d9304bd3f78d29ee718bf637b15bbe8b9743d5f0e15fd"
  },
  {
    "id": "/science/2019/05/17/arguments.html",
    "title": "论证笔记",
    "content": "The content discusses the nature of arguments and different types of arguments. It begins by defining an argument as a set of sentences, where one is being asserted as true and the others are offered as reasons for believing the truth of the asserted sentence. Examples are provided to illustrate the structure of an argument, with the conclusion being the sentence said to be true and the premises being the sentences offered as reasons. It is emphasized that the function of a sentence in an argument determines whether it is a conclusion or a premise. Sets of sentences that do not have a relation between them or have a relation other than that characterizing an argument are not considered arguments. Furthermore, it is explained that an argument can be made by claiming one sentence to be true and offering other sentences as support, but the relationship between the sentences is what determines whether or not it forms an argument. The distinction between arguments and assertions is also discussed, with arguments being sets of sentences where one is being asserted and assertions being single sentences expressing a belief. The concept of truth is explored, with the notion that only beliefs or sentences that express beliefs can be true or false, while arguments can only be good or bad. Three separate levels of language, thought, and reality are identified, and it is explained that arguments can be made and discussed at each level. The characteristics of a good argument are also highlighted, including the requirement for the conclusion to follow from the premises. The content then delves into different types of arguments, starting with deductive arguments, which are characterized by the truth of their premises guaranteeing the truth of their conclusion. Inductive arguments, on the other hand, are said to make the conclusion more or less probable based on the truth of their premises. The distinction between deductive and inductive arguments is further emphasized, with deductive arguments being more certain while inductive arguments are not. Various forms of deduction and induction are discussed, including analog arguments and cause arguments. The content concludes with a section on setting out arguments in a logic-book-style format, which involves identifying the conclusion and premises, adding suppressed premises, removing irrelevancies and inconsistent terms, and removing cross-references. The ten most important keywords are: argument, conclusion, premises, deductive argument, inductive argument, forms of deduction, forms of induction, analog arguments, cause arguments, and logic-book-style.",
    "sha256": "a51780d4c31b1fdb3cc4220889bbd9b19355b7fb0b4466df8cb7ab4ccc13c665"
  },
  {
    "id": "/science/2020/11/02/pbc_py.html",
    "title": "Pairwise distance with PBC",
    "content": "When simulating a system using molecular dynamics or Monte-Carlo sampling, the periodic boundary condition (PBC) is often used to maintain the volume fraction of the system. In Python, there are multiple ways to implement the PBC, and this post introduces three different implementations.   The first method involves calculating the pair distances within a for loop. This method is straightforward but slow due to the use of Python, taking about 5000 ms to complete.   The second method, inspired by Francescos post, utilizes the fast function pdist from the scipy package to calculate the pair distances. This implementation is significantly faster, taking about 800 ms to complete.   The third method, from Allen  Tildesleys book, also provides a good implementation. While it is not as efficient as the second method, taking about 900 ms to complete, it offers access to the pairwise shift during calculation, which is useful for implementing agent-based models.   Additionally, the post provides a more compact version of the third method using numpy broadcasting rules.   The author compares the three methods and finds that they produce identical results, but vary in efficiency. The second method is the most efficient, taking only 0.0230 s to complete.   The important keywords are: periodic boundary condition, molecular dynamics, Monte-Carlo sampling, PBC, pairwise potentials, Lennard-Jones potential, pair distances, straightforward way, faster implementation, example python code, numpy broadcasting rules, efficiency.",
    "sha256": "313e83301db0cd9fcf9f16a0ad5d48bb6d52f0edf26ab849c333d11ec41ac2f0"
  },
  {
    "id": "/code/2020/11/15/ml.html",
    "title": "机器学习",
    "content": "The provided markdown post discusses three different topics: Simplex, Nuclear Norm and Spectral Norm, and Keras Functional API.   In the section about Simplex, the concept of a simplex in mathematics is introduced and defined as a set of points in a space where each component is non-negative and the sum of the components is equal to one. The geometric interpretation in different dimensions is also explained.  The section on Nuclear Norm and Spectral Norm explains the definitions and functionalities of the nuclear norm and spectral norm for matrices. Code examples in Python using the Numpy library are provided to compute these norms. Pseudocode is also given to illustrate how to perform nuclear norm minimization and constrained optimization with spectral norm. The connection between these norms and semidefinite programming (SDP) is also discussed.  Lastly, the section on Keras Functional API discusses the functional programming style for building neural network models in the Keras module of TensorFlow 2. It compares the procedural style with the functional style and provides code examples in both styles. The use of layers and the creation of a model using the functional API are explained in detail.  The 10 most important keywords are: Simplex, 单纯形 (Simplex), geometric interpretation, probability, nuclear norm, trace norm, spectral norm, Keras Functional API, sequential, and functional API.",
    "sha256": "144aaeb7e358fbb261ab3362da07881b0312ba817bff324c9973d19a479cf7e7"
  },
  {
    "id": "/science/2021/04/04/image-der.html",
    "title": "Modeling Confocal Images",
    "content": "The provided content discusses a model for simulating confocal microscopy images of particles. The model represents each particle as a hard sphere with Gaussian blur in 3D. The contribution of each particle to the image is calculated using the product of its intensity, a Platonic particle without blur, and a Gaussian kernel. The model of the confocal image can be expressed as the sum of these contributions. The content also provides pseudo-code for simulating a confocal image based on a collection of particle locations, radii, and intensity values.   The content then focuses on the derivative of the model and its applications. It introduces the cost function for comparing the model with experimental data and explains that a good model should minimize the squared difference between the model and experimental image. The cost function is a sum over all voxels, where the difference between the experimental image and simulation is weighted by mathrmW. The derivative of the cost function with respect to particle locations is derived, showing that it depends on the derivative of the simulated intensity values and the derivative of the Gaussian blur with respect to the particle locations. The content further simplifies the derivative by considering that the intensity and shape of a particle are not affected by the location of another particle.   The content then presents the numerical implementation of the cost function and its use in updating the particle locations using least square optimization.   In summary, the content discusses a model for simulating confocal microscopy images of particles using a hard sphere with Gaussian blur representation. It explains the calculation of the image contribution for each particle and provides pseudo-code for simulating the image. It also covers the derivative of the model and its application in finding particle locations. Finally, it presents the numerical implementation and use of the cost function.   Keywords: confocal microscopy, particles, hard sphere, Gaussian blur, image simulation, intensity, Platonic particle, Gaussian kernel, cost function, derivative, experimental data, simulated image, numerical implementation, particle locations, least square optimization.",
    "sha256": "7f49824913d93c746ca56e00c39fffc90c1da0be67c83ed38c1e9d7af82e2054"
  },
  {
    "id": "/science/2023/09/08/stat-phy.html",
    "title": "统计物理",
    "content": "The provided content is a Markdown post discussing the Van Hove correlation function and the scaling hypothesis in statistical mechanics. The post begins by introducing the formula for the Van Hove correlation function, which describes the average probability of finding a particle at a certain position at time t given that another particle is at a different position at time 0. The post goes on to explain the relationship between the Van Hove correlation function and the radial distribution function, as well as the distinction between the self and distinct parts of the function. The normalization conditions for the correlation functions are also discussed.   In the second part of the post, the scaling hypothesis is introduced as a way to understand the relationship between magnetization, external magnetic field, temperature, and the critical temperature. The experimental results for magnetization, susceptibility, and scaling functions are presented, followed by the derivation of three relationships using the scaling hypothesis. These relationships involve the magnetization, susceptibility, and scaling functions in different limits. The post concludes by mentioning the predictions made by the scaling hypothesis, including the critical exponents and their relations, which have been experimentally and theoretically verified. The scaling function, although not explicitly described, is mentioned to have a specific shape that can be numerically determined. Overall, the post provides a detailed explanation of the Van Hove correlation function and the scaling hypothesis in statistical mechanics.  Keywords: Van Hove correlation function, density correlation, spatial correlation, temporal correlation, self, distinct, radial distribution function, normalization, scaling hypothesis, magnetization, external magnetic field, temperature, critical temperature, susceptibility, scaling function, critical exponents, relations, experimental verification, theoretical verification.",
    "sha256": "d7c20075f2c788b48638467c2fc5e5c20c005a59a7168b3834e6785e8d92d49a"
  },
  {
    "id": "/code/2020/10/22/hpc.html",
    "title": "Useful Linux Commands",
    "content": "This markdown post provides various useful commands and instructions for managing files, running processes, and configuring tools in a Linux environment. The post includes descriptions and examples of commands such as `rsync` for synchronizing files, `nohup` for running processes in the background, `pbcopy` for copying input to the clipboard on macOS, `xclip` for interacting with the X11 clipboard on Linux, and more. It also includes commands for tasks such as checking file sizes (`ls -l --block-size=M`, `du -sh .`), generating hashes (`shasum`, `md5`, `openssl md5`), batch converting image formats (`mogrify -format tif *.png`), displaying images (`display picture.png`), configuring Vim compilation, and compiling Python 3.8. It also provides commands for transferring files between local and remote machines using `scp`, as well as instructions for using more memory in an HPC (high-performance computing) environment. Important keywords include `rsync`, `nohup`, `pbcopy`, `xclip`, file size, hash, batch convert, display image, Vim compilation, Python compilation, HPC, transfer files, and use more memory.",
    "sha256": "672b8fadab99b238214d589cc4e50a535bf9458b49d85b3cc43d2e2450e11bf5"
  },
  {
    "id": "/science/2020/04/28/vicsek-noise.html",
    "title": "Noise in 3D Vicsek model",
    "content": "This post discusses the implementation of the Vicsek model algorithm in 3D and introduces a method for generating the necessary noise for rotating vectors. The noise is generated by rotating the target direction by a random direction. The post provides math equations to address this process and explains that in the 2D case, the angle of the vector is modified by adding a random angle from a uniform distribution. However, in 3D, things are more complex. The post includes visual graphs to illustrate the effect of the rotation operator and explains the steps to perform this operation. The post then introduces a practical way to generate scalar noise in 3D by generating uniformly distributed noise and rotating it to the direction of the vector. Python code is provided to generate the noise in 3D, and the code is explained in detail. The post also discusses how to pick random points on a sphere and provides the relationship between the noise level and the range of the uniform distribution. Finally, the post explains the rotation process and provides a step-by-step tutorial along with the necessary math equations and illustrations.   Keywords: Vicsek model, noise generation, 3D, rotating vectors, math equations, uniform distribution, scalar noise, Python code, random points on a sphere, rotation process.",
    "sha256": "6518fb104356675a661393916339ade9a301578cbe86845af5369a4f3f87abca"
  },
  {
    "id": "/code/2021/12/17/raw-npy.html",
    "title": "Open NPY in ImageJ",
    "content": "This post provides instructions on how to correctly import NPY files, which are binary representations of Numpy arrays, into ImageJ or FIJI software. The NPY file consists of a header section that contains information about the array, and the raw data section that represents the values in the array. To load the NPY file in ImageJ or FIJI, the user must use the File > Import > Raw option. The user needs to input the correct numbers for width, height, and number of images, taking into account that the order of axes in ImageJ/FIJI is reversed compared to Numpy. Additionally, the user needs to set the Offset to first Image to a value that is divisible by 16, usually 128. The post explains how to determine the length of the header using a hex editor, and provides a code example to dump the array without the header using the `tofile` method in Numpy. Overall, the post offers detailed instructions on how to import NPY files into ImageJ or FIJI, including handling the header length and alternative methods for loading the raw data. The 10 most important keywords are: NPY file, Numpy array, ImageJ, FIJI, header, raw data, File > Import > Raw, axes, Offset to first Image, and tofile method.",
    "sha256": "ddd55b9b5cd6269669ff72aa76d7dafad6aa75db03b388f49c3d5664d5b61e47"
  },
  {
    "id": "/code/2020/03/04/opencv-undistort.html",
    "title": "Opencv Camera Distortion",
    "content": "This post discusses the distortion coefficients used in camera calibration, specifically focusing on how to distort and undistort features in an image without using functions in the OpenCV library. The tutorial provided by OpenCV gives equations for correcting the distortion, but when the equations are implemented, the results are incorrect. An alternative version from a Matlab tutorial shows the correct equations. By examining the source code of OpenCV, it is confirmed that the equations in the OpenCV tutorial are not correct. The post provides a correct implementation of the distortion correction algorithm and shows the correct undistorted results. The keywords for this post are camera calibration, distortion coefficients, undistortion, OpenCV, equations, implementation, source code, correct results, Matlab tutorial.",
    "sha256": "cea620378e3c865cf3b693317212599e6c4d7a479dbc89b2350b84ef57b3aecf"
  },
  {
    "id": "/idea/2022/02/07/read.html",
    "title": "读书笔记",
    "content": "The post discusses the book Meditations by Marcus Aurelius and focuses on a thought-provoking speculation about death mentioned in the book. Marcus Aurelius was a Roman emperor and a philosopher of the Stoic school. In the 10th volume of Meditations, he writes that no one is so fortunate that there wont be someone pleased with their death when they are dying. This idea suggests that even in death, some people may find happiness, unless the deceased person is exceptionally lucky. This dark speculation challenges the commonly held belief that loved ones would mourn our deaths. Marcus Aurelius suggests that we should reflect on this idea and depart from life with contentment, not clinging to it. He emphasizes that we can only change our own thoughts, and it is important to cultivate virtues such as kindness and gentleness without expecting friendship to be a transactional relationship. The post also briefly mentions The School of Life video about Stoicism and lists some common fallacies from the book The Illustrated Book of Bad Arguments. The fallacies include vague generalizations, causal confusion, false dilemmas, circular reasoning, appeal to ignorance, and many others. The detailed explanations and examples of each fallacy are provided.   Keywords: Meditations, Marcus Aurelius, Stoic philosophy, death, speculation, fortunate, dark, thought-provoking, emotions, loved ones, mourning, contentment, virtues, kindness, gentleness, friendship, transactional relationship, The School of Life, Stoicism, fallacies, vague generalizations, causal confusion, false dilemmas, circular reasoning, appeal to ignorance, examples.",
    "sha256": "80624bb25d07d34644f96ce7dab097cf2495bf6a76e06af4ec657026fad64641"
  },
  {
    "id": "/code/2020/06/26/cpp-library.html",
    "title": "Create a C++ Library",
    "content": "This markdown post provides a detailed guide on how to create static and dynamic libraries in C++. The author shares their personal experience of being confused about the C++ library ecosystem and not being able to compile open-source libraries. The post includes example code consisting of three files: `hello_world.h`, `hello_world.cpp`, and `main.cpp`, with the goal of creating a library for `hello_world` that can be used by `main.cpp`. The post then provides instructions for compiling the code with and without the library.  The normal way to compile the code is described, where the `main.cpp` and `hello_world.cpp` files are compiled together using the `g++` command in a Bash script called `compile.sh`. After running the script, the executable `out` is created and executed, resulting in the output Hello World!. The script also includes commands to remove the executable.  The post then explains how to create a static library using the `ar` command. The `hello_world.cpp` file is compiled using the `-c` flag to generate an object file, and then the object file is archived into `libhello_world.a`. The `main.cpp` file is compiled using the `libhello_world.a` library instead of the `hello_world.cpp` file, resulting in the same Hello World! output. The commands to remove the library and the executable are provided.  Next, the post discusses creating a shared library. The `hello_world.cpp` file is again compiled, this time with the `-fPIC` flag to enable sharing, producing an object file named `hello_world.o`. The object file is then used to create a shared library `libhello_world.so` using the `-shared` flag. The `main.cpp` file is compiled with the `-L` flag to specify the library path and the `-l` flag to specify the library name as `hello_world` (ignoring the `lib` prefix and `.so` suffix). The resulting executable, `out`, when executed, prints Hello World!. The commands to remove the object file and the executable are provided.  The keywords for this summary are: C++, eco-system, open source library, static library, dynamic library, compile options, library path configuration, source code, compilation, script, executable, static library archive, object files, shared library, linking, run time, `g++`, `ar`, `-c`, `-fPIC`, `-shared`, `-o`, `-L`, `-l`.",
    "sha256": "8c0a40992d5eb82f40bc773f8424393067ab716b47c09cedc016002618b13b3d"
  },
  {
    "id": "/code/2023/09/09/enum-py-cpp.html",
    "title": "Enumeration in Python/C++",
    "content": "The provided content explains the concept of enumerations (enums) and their usage in Python and C++. Enums are used to represent a set of named values and improve code readability by replacing magic numbers or strings with named constants. The content first introduces the general concept of enums and provides pseudo-code to demonstrate how they can be used. It then focuses on Pythons `enum.Enum`, highlighting its features such as flexible values (enums can be associated with integers, strings, tuples, or other constant values), type-safe comparisons, iterability, and the ability to have methods and attributes. Several examples are provided, including basic enumerations, enums with flexible values, auto value assignment, iterating over enums, and having methods within enums.   The second part of the content discusses C++ enums. It mentions features such as the integral underlying type (enum values are restricted to integral types), scoped enums (better type safety and scope management), and conversions (traditional enums can be implicitly converted to integers, but enum class members require explicit casting). Examples of basic enumerations, scoped enums with specific underlying types, accessing and comparisons, and creating a custom enum using classes are provided.   10 most important keywords: enumerations, enums, named values, code readability, magic numbers, named constants, Python `enum.Enum`, flexible values, type-safe comparisons, C++ `enum`.",
    "sha256": "e6efd97d3d1d7b1e7d12d2ac7dacf6e16951c68fb0ffffb5a8af444645f079cb"
  },
  {
    "id": "/code/2023/09/07/jupyter-notebook.html",
    "title": "Jupyter Notebook Tricks",
    "content": "The provided markdown post covers several topics related to using Jupyter Notebook. It starts by explaining how to reload modules in a Jupyter Notebook using the `%load_ext autoreload` and `%autoreload 2` commands, which ensure that modifications made to a modules code are immediately reflected in the notebooks output. Next, it discusses how to install and uninstall Python kernels for different versions of Python, allowing the user to use them separately and clearly in Jupyter Notebook. The installation process involves using the `ipykernel` package and running `python -m ipykernel install --user --name NAME --display-name NAME`, while uninstallation can be done using `jupyter kernelspec uninstall NAME`. The post then tackles the topic of inserting images into markdown cells. By default, using `!(link_to_image)` inserts an image with a fixed size, but to specify the image size, the user needs to write HTML code, like `<img src=image alt=Drawing style=width: 200px;/>`. However, this rendering method may not work on GitHub. Finally, the post provides instructions on how to connect to the BlueCrystal High-Performance Computing (HPC) system at the University of Bristol using Jupyter Notebook. It involves starting the notebook on BlueCrystal, forwarding the remote port to the local machine, and accessing the notebook through a browser using the provided link. The ten most important keywords are: reload modules, install, uninstall, kernel, Python versions, image, resize, connecting, BlueCrystal, Jupyter Notebook.",
    "sha256": "86dcb3592b4d8304fa93f7b3bd33962b907822a62ae03d426a540968e05a190d"
  },
  {
    "id": "/code/2020/03/02/vim-desktop.html",
    "title": "Vim Desktop in Ubuntu ",
    "content": "The purpose of this markdown post is to explain how to create a desktop file that allows for the use of the latest vim built from the source on a personal working PC. The post provides instructions on creating the desktop file in the `~/.local/share/applications` folder and includes the necessary code to open a file in vim by clicking the file icon. However, simply using the code provided is not enough to make the desktop start up, so the post goes on to explain how to handle this issue. One solution is to modify the `Exec` line in the `.desktop` file to include `bash -c vim %F;exec SHELL`, which prevents the terminal from closing. Another issue to consider is inheriting custom environment variables from the `.bashrc` file. To accomplish this, the `Exec` line can be modified to include `bash -c source ~/.bashrc  vim %F;exec SHELL`. However, caution must be taken with the `.bashrc` file, as certain code blocks need to be placed before any environmental variable declarations in order for the environment to affect the terminal called by the desktop. The post concludes by providing the final version of the `.desktop` file, which includes the necessary modifications and additional details such as the encoding, name, comment, icon, and categories of the application.   Keywords: vim, source, desktop file, file icon, terminal, prevent closing, custom environment, bashrc, variables, code blocks",
    "sha256": "deabaae17a7e98e5ca9a9f9866a3f5241449d4d7eec7d77d37f3cd99fbcfda2d"
  },
  {
    "id": "/code/2017/12/09/struct.html",
    "title": "Python Module Struct",
    "content": "The provided markdown post introduces the `struct` module in Python, which is used to work with binary data. It explains three important methods of this module: `pack`, `calcsize`, and `unpack`. The `pack` method allows us to encode numerical data into formatted binary data. It takes a format string and the values to be packed as arguments and returns a bytes object containing the packed values. An example code snippet is given to demonstrate this functionality. The `calcsize` method is used to determine the size of the struct and the corresponding bytes object produced by `pack`. It takes a format string as an argument and returns the size in bytes. Several example format strings are provided along with their corresponding sizes. Finally, the `unpack` method is used to unpack a buffer of packed data according to a given format string. It takes a format string and the buffer as arguments and returns a tuple of unpacked values. An example code snippet and its corresponding unpacked values are provided to illustrate this functionality. The ten most important keywords in this content are: struct, module, binary data, pack, calcsize, unpack, format string, bytes object, numerical data, and buffer.",
    "sha256": "7796735a1957b289f00aff62c3c67b050122272c67e17f2006a641d607180a89"
  },
  {
    "id": "/code/2021/01/13/connect-pi.html",
    "title": "Connecting Raspeberry Pi",
    "content": "This markdown post describes the process of connecting to a Raspberry Pi from a Ubuntu PC using an ethernet connection. The Raspberry Pi has the Raspberry Pi OS installed and the user spends a significant amount of time figuring out the connection. The post begins by enabling all interfaces on the Raspberry Pi and then using the SSH command `ssh pi@raspberrypi.local` to establish a connection. There are some warnings encountered, so the user runs the command `ssh-keygen -f /home/yushi/.ssh/known_hosts -R raspberrypi.local` to address them. After running the SSH command again, the user is prompted for the default password on the chip, which is raspberry, and the SSH connection is successfully established. The post also mentions the convenience of using VNC Viewer to access the Raspberry Pis desktop. The user installs VNC Viewer on their Ubuntu PC and creates a new connection by entering raspberrypi.local in the VNC Server entry. After providing the username and password, the connection is established.   Keywords: Raspberry Pi, Ubuntu PC, ethernet connection, Raspberry Pi OS, SSH, VNC Viewer, desktop, WIFI networks.",
    "sha256": "2d3bea2fdc939a884b61159649c8f6bc484abdea39c52d7c62ba1253b60bb7e1"
  },
  {
    "id": "/code/2020/02/09/ffmpeg.html",
    "title": "Video Editing",
    "content": "This post provides a collection of useful commands using `ffmpeg` to process videos in the terminal. The author mentions that memorizing these commands is difficult, so they share them here. The commands cover various tasks, such as cutting videos, extracting the first frame, adjusting gamma, removing audio, changing frame rate, generating videos from images, and extracting information about frames and frame rate. The author also includes a command using ImageMagick to create gifs from images. The keywords for this post are ffmpeg, video processing, terminal, command line, cut video, get first frame, change gamma, drop sound, change frame rate, generate video, total frames, frame rate, generate gif, ImageMagick.",
    "sha256": "1e2be2c0eec9c6f4ba55e2d2a01d8f91c79ab1b44bd545dfc3111f51a79e6b75"
  },
  {
    "id": "/work/2023/08/18/barcode.html",
    "title": "二代测序",
    "content": "This markdown post discusses the use of barcodes in sequencing to distinguish DNA fragments from different samples. The post explains that DNA consists of two complementary strands and each strand has a 5 and a 3 end. It also mentions that the standard direction of DNA sequencing is from the 5 end to the 3 end. The post then introduces Pair Ended (PE) sequencing, which provides sequence information from both ends of a fragment to determine its orientation and distance. An example DNA fragment is given along with its sequencing results. The post then describes two barcode splitting strategies: single barcode at one end of the fragment and double barcode at both ends. An example for each strategy is provided along with the resulting sequencing reads. Lastly, the post mentions the concept of single-read barcode, where a barcode is only added to a specific read (e.g., Read1) in paired-end sequencing. The post concludes by providing an example of a fragment with a single-read barcode and its sequencing read. The 10 most important keywords are: barcode, DNA, sequencing, fragment, PE sequencing, DNA strands, 5 end, 3 end, single-read barcode, and paired-end sequencing.",
    "sha256": "a2d4d178d23f6878fccbc28941b890d843673681df04caccec9e545d48939490"
  },
  {
    "id": "/code/2023/09/18/chatgpt.html",
    "title": "ChatGPT Prompts",
    "content": "When you ask for an explanation of a command, the ideal response should include a quick overview of the basic syntax, an explanation of the syntax, a simple example, a text description of the command, and a text description of how the command works. For example, if you ask about the `nohup` command, the response would provide the following information:  Command: `nohup COMMAND ARG... ` - `COMMAND`: The command you want to run. - `ARG`: Optional arguments for the command. - ``: Used to run the command in the background.  Example: ```bash nohup python my_script.py  ```  The `nohup` command in Linux allows you to run a process in the background and ensures that it keeps running even after youve logged out. The term nohup stands for No Hang Up. When you run a command with `nohup`, it detaches the process from the terminal and redirects the standard output (`stdout`) and standard error (`stderr`) to a file, usually `nohup.out`.  Keywords: explain, command, syntax, example, description, works, nohup, Linux, process, background.",
    "sha256": "b5dfe8a95ac761cbd14f0a626c7ed7b23667da7648bdbbeba4a1bf8226c5be37"
  }
]