<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <title>机器学习</title>
    <link rel="stylesheet" href="/assets/css/styles.css">
    <link rel="stylesheet" href="/assets/css/styles/github-gist.css">
    <script src="/assets/js/toc.js"></script>
    <script src="/assets/js/highlight.pack.js"></script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"] ],
          processEscapes: true
        }
      });
    </script>

    <script type="text/javascript" id="MathJax-script" async
            src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
      >
    </script>
    
    </head>

  <body>
    <script>hljs.initHighlightingOnLoad();</script>
    
    <nav>
    <ul>
        
        <li>
        <a href=/
            
        >
            Home
        </a>
        </li>
        
        <li>
        <a href=/notebook_en.html
            
        >
            Notebook
        </a>
        </li>
        
        <li>
        <a href=/notebook_cn.html
            
        >
            笔记本
        </a>
        </li>
        
    </ul>
</nav>


    <div class="main">
        <div id="side_bar">
    15 Nov 2020
</div>

<div class="center post">
    <ul id="markdown-toc">
  <li><a href="#单纯形-simplex" id="markdown-toc-单纯形-simplex">单纯形 (Simplex)</a>    <ul>
      <li><a href="#定义" id="markdown-toc-定义">定义</a></li>
      <li><a href="#几何解释" id="markdown-toc-几何解释">几何解释</a></li>
      <li><a href="#与概率的关系" id="markdown-toc-与概率的关系">与概率的关系</a></li>
      <li><a href="#单纯复合体" id="markdown-toc-单纯复合体">单纯复合体</a></li>
    </ul>
  </li>
  <li><a href="#核范数与谱范数" id="markdown-toc-核范数与谱范数">核范数与谱范数</a>    <ul>
      <li><a href="#核范数" id="markdown-toc-核范数">核范数</a></li>
      <li><a href="#谱范数" id="markdown-toc-谱范数">谱范数</a></li>
      <li><a href="#半定规划sdp" id="markdown-toc-半定规划sdp">半定规划（SDP）</a></li>
    </ul>
  </li>
  <li><a href="#keras-函数式-api" id="markdown-toc-keras-函数式-api">Keras 函数式 API</a>    <ul>
      <li><a href="#面向对象-api" id="markdown-toc-面向对象-api">面向对象 API</a></li>
      <li><a href="#函数式-api" id="markdown-toc-函数式-api">函数式 API</a></li>
      <li><a href="#深入理解" id="markdown-toc-深入理解">深入理解</a></li>
      <li><a href="#附录没有输入的模型" id="markdown-toc-附录没有输入的模型">附录：没有输入的模型</a></li>
    </ul>
  </li>
</ul>

<h2 id="单纯形-simplex">单纯形 (Simplex)</h2>

<p><strong>单纯形 (Simplex)</strong> 在数学中是一个基本概念，通常使用 $ \Delta $ 来表示。</p>

<h3 id="定义">定义</h3>

<p>在 $ \mathbb{R}^K $ 中的<strong>单纯形</strong>是所有点 $ p $ 的集合，使得：</p>

<ul>
  <li>每个组件 $ p_k $ 都是非负的：对于所有 $ k $，都有 $ p_k \geq 0 $。</li>
  <li>组件的总和为一：$ \sum_{k=1}^{K} p_k = 1 $。</li>
</ul>

<p>数学上，这可以表示为：</p>

\[\Delta^{K-1} = \{ p \in \mathbb{R}^K : p_k \geq 0, \sum_{k=1}^{K} p_k = 1 \}\]

<h3 id="几何解释">几何解释</h3>

<ul>
  <li>在 $ \mathbb{R}^2 $（2D空间）中，单纯形是一个线段。</li>
  <li>在 $ \mathbb{R}^3 $（3D空间）中，它是一个三角形。</li>
  <li>在 $ \mathbb{R}^4 $ 中，它是一个四面体。</li>
  <li>以此类推…</li>
</ul>

<h3 id="与概率的关系">与概率的关系</h3>

<p>单纯形与概率分布有着密切的关系：</p>
<ul>
  <li>$ (K-1) $-维单纯形中的一个点对应于 $ K $ 个结果上的概率分布。</li>
  <li>例如，在 $ \mathbb{R}^3 $ 中，单纯形中的一个点可以表示三个事件上的概率分布。</li>
</ul>

<h3 id="单纯复合体">单纯复合体</h3>

<p><strong>单纯复合体</strong>是由顶点、线段、三角形及其 $ n $-维对应物组成的集合。它是单纯形概念的推广，可以表示由各种维度的单纯形填充的空间。</p>

<h2 id="核范数与谱范数">核范数与谱范数</h2>

<h3 id="核范数">核范数</h3>

<p>对于矩阵$A$，其核范数（Nuclear Norm 或者 Trace Norm，通常记作 $|A|_*$）是其奇异值的总和。</p>

<p><strong>使用Numpy的Python示例</strong>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">def</span> <span class="nf">compute_nuclear_norm</span><span class="p">(</span><span class="n">A</span><span class="p">):</span>
    <span class="n">singular_values</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">svd</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">compute_uv</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">singular_values</span><span class="p">)</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">compute_nuclear_norm</span><span class="p">(</span><span class="n">A</span><span class="p">))</span>
</code></pre></div></div>

<p><strong>核范数最小化的伪代码</strong>:</p>

<p>核范数可以作为矩阵秩在优化问题中的凸替代。</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>function NuclearNormMinimization(A, mask):
    使用零初始化矩阵 X
    当未达到收敛条件:
        # 梯度步骤: 逼近已知条目
        基于A的条目（mask为True的地方）更新X
        # 收缩步骤: 促进低秩
        对X应用SVD并缩小奇异值
    return X
</code></pre></div></div>

<h3 id="谱范数">谱范数</h3>

<p>对于矩阵 $A$，其谱范数（spectral norm, 通常记作 $|A|_2$）是其最大的奇异值。</p>

<p>使用 Numpy 的 Python 示例:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">def</span> <span class="nf">compute_spectral_norm</span><span class="p">(</span><span class="n">A</span><span class="p">):</span>
    <span class="n">singular_values</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">svd</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">compute_uv</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">singular_values</span><span class="p">)</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">compute_spectral_norm</span><span class="p">(</span><span class="n">A</span><span class="p">))</span>
</code></pre></div></div>

<p><strong>带有谱范数约束的优化的伪代码</strong>:</p>

<p>谱范数可以用作优化问题中的约束，以界定矩阵的“大小”或“效果”。</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>function SpectralNormConstrainedOptimization(A, gamma):
    使用零初始化矩阵 X
    当未达到收敛条件:
        # 梯度步骤: 逼近目标
        更新 X
        # 投影步骤: 确保谱范数约束
        如果 SpectralNorm(X) &gt; gamma:
            缩放X以满足谱范数 &lt;= gamma
    return X
</code></pre></div></div>

<h3 id="半定规划sdp">半定规划（SDP）</h3>

<p>核范数和谱范数都可以整合到形式化为 SDP 的优化问题中。</p>

<p><strong>带有核范数最小化的SDP的伪代码</strong>:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>function SDPWithNuclearNorm(A):
    初始化半定矩阵 Y
    当未达到收敛条件:
        # 梯度步骤: 逼近数据拟合
        基于A更新Y
        # 收缩步骤: 促进结构
        对Y应用某些操作以鼓励所需结构
    return Y
</code></pre></div></div>

<h2 id="keras-函数式-api">Keras 函数式 API</h2>

<p>深度学习库 Tensorflow 2 里的 Keras 模块提供了函数式<small>（泛函）</small> 风格的 应用程序接口 (API)。这让我们可以用相当不同的风格，构建出同样的神经网络模型。这个笔记比较了两种风格，基于对应的 <a href="https://www.tensorflow.org/guide/keras/functional">tensorflow 文档</a>。</p>

<h3 id="面向对象-api">面向对象 API</h3>

<p>Keras 里我们可以用下面的代码创建模型。这里的代码是过程式的（普通的）。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">([</span>
<span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Input</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="p">),</span>
<span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">layer1</span><span class="sh">"</span><span class="p">),</span>
<span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">layer2</span><span class="sh">"</span><span class="p">),</span>
        <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">layer3</span><span class="sh">"</span><span class="p">),</span>
<span class="p">])</span>
<span class="n">model</span><span class="p">.</span><span class="nf">summary</span><span class="p">()</span>
</code></pre></div></div>

<p>这一块代码相当容易理解。我调用了 <code class="language-plaintext highlighter-rouge">tf.keras.layers</code> 里的函数（<code class="language-plaintext highlighter-rouge">Dense</code>），得到了不同的三个「层」。之后 <code class="language-plaintext highlighter-rouge">Sequential</code> 函数把这些「层」依序连接起来，得到了结果。这个模型的 <code class="language-plaintext highlighter-rouge">summary</code> 如下，</p>

<pre class="asciiart">

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
layer1 (Dense)               (None, 2)                 12        
_________________________________________________________________
layer2 (Dense)               (None, 3)                 9         
_________________________________________________________________
layer3 (Dense)               (None, 4)                 16        
=================================================================
Total params: 37
Trainable params: 37
Non-trainable params: 0
_________________________________________________________________

</pre>

<p>第一层的参数是 <strong>12</strong> 的原因是我们有 <strong>2</strong> 个神经元，每个神经元 连接了 <strong>5</strong> 个输入，所有总共有 $2 \times 5 = 10$ 个 权重值。再加上 <strong>2</strong> 个属于神经元的偏差，最终得到 <strong>12</strong> 个参数。</p>

<h3 id="函数式-api">函数式 API</h3>

<p>Keras 同时也允许我们把 同样的代码 用<a href="https://zh.wikipedia.org/wiki/函数式编程">函数式风格</a>写出来。写法如下，</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">layer1</span><span class="sh">"</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">layer2</span><span class="sh">"</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">layer3</span><span class="sh">"</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="nc">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nf">summary</span><span class="p">()</span>
</code></pre></div></div>

<p>这会得到同样的模型。</p>

<h3 id="深入理解">深入理解</h3>

<p>在面向对象 API 里，我们的使用的语法如下</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span>
  <span class="p">[</span><span class="n">输入</span><span class="p">,</span> <span class="n">第一层</span><span class="p">,</span> <span class="n">第二层</span><span class="p">,</span> <span class="n">第三层</span><span class="p">,...]</span>
<span class="p">)</span>
</code></pre></div></div>

<p>其中，我们使用函数得到了不同「层」，我把我得到的东西想象成对象。下面是我们得到「第一层」的语句。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">第一层</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">"</span><span class="s">relu</span><span class="sh">"</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">layer1</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p>这样的想象是对的，不过 <code class="language-plaintext highlighter-rouge">tf.keras.layers</code> 里的函数返回给我们的实际上是，另一个函数。下面的代码解释了这个行为。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>

<span class="n">l1</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">l2</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">l3</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="nf">l3</span><span class="p">(</span><span class="nf">l2</span><span class="p">(</span><span class="nf">l1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>  <span class="c1"># shape 1, 4
</span></code></pre></div></div>

<p>我们可以用 数学公式 表示最后一行代码</p>

\[\begin{aligned}
x_1 &amp;= l_1(x)\\
x_2 &amp;= l_2(x_1)\\
y &amp;= l_3(x_2)
\end{aligned}\]

<h3 id="附录没有输入的模型">附录：没有输入的模型</h3>

<p>在我创建模型的时候，我通常会指定输入数据的形状。譬如，下面的代码 将 输入数据 固定为 5 个数字。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Input</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="p">)</span>
</code></pre></div></div>

<p>但是，我也可以创造一个没有输入的模型。一个最简单的例子如下，</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">([</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="p">])</span>
</code></pre></div></div>

<p>此时，我们不能直接使用 <code class="language-plaintext highlighter-rouge">model.summary()</code> 来得到模型的描述。因为我们不知道 输入数据的结构，因而无法确定 模型中 参数的数目。同时我会得到这样的错误警告：</p>

<pre class="asciiart">
ValueError: This model has not yet been built. Build the model
first by calling `build()` or calling `fit()` with some data, or
specify an `input_shape` argument in the first layer(s) for automatic build.
</pre>

<p>当我“使用”过一次模型之后，模型的输入就会被确定。譬如，下面的代码片段可以顺利执行。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">([</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nf">summary</span><span class="p">()</span>
</code></pre></div></div>

<p>我们「不能」将模型套用在「形状不同的输入」上。譬如，下面的代码会产生错误。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">([</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1">#  顺利执行，模型的输入被固定为 5
</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1">#  程序报错
</span></code></pre></div></div>

</div>


    </div>

  </body>

</html>
